What it is like to be a forensic psychologist?

I can only imagine that many cases are routine: the suicide of a sick and lonely debtor, the crime of passion against an unfaithful spouse, the slaying of a rival gang member. While reprehensible, these crimes are fundamentally explicable. While condemning them, we can grant the perpetrators the dignity of a form of rationality. The suicide longed for an end to his pain, the jealous husband raged against betrayal, the gang member dreamed of triumph and glory—and they acted accordingly. Such tragedies will probably always be with us at some frequency as long as humans remain what they are.

----

^^^ Maybe this is still usable? 

-----

wait, what? Does he not understand the concept of adversarial debate?
https://www.lesswrong.com/posts/98sCTsGJZ77WgQ6nE/banning-said-achmiz-and-broader-thoughts-on-moderation?commentId=WiE6LsKjbTzjfJeFM
> Why oh why would it somehow no longer be part of appropriate conduct to be a reasonable interlocutor trying to help readers come to true beliefs if you are in the process of getting banned?


"Said doesn't think

https://www.lesswrong.com/posts/6dmKBjc7XarcQMRYW/being-wrong-doesn-t-mean-you-re-stupid-and-bad-probably

--

[reply to DirectedEvolution: https://www.greaterwrong.com/posts/98sCTsGJZ77WgQ6nE/banning-said-achmiz-and-broader-thoughts-on-moderation/comment/GjtZY7pg9LRB2mwMi]

> delivering valid and empathetic criticism

What is the word _empathetic_ doing in this phrase? Why should I care about whether criticism is "empathetic"? _Reply!_

> Do you not care about developing community? Do you simply have better things to do and want to freeload on the community that others build?

What do you mean by "community"? I care about arguring about ideas on the internet. That doesn't necessarily put me in a "community" with the people I'm arguing with in any meaningful sense.

To me, the prototypical referent of the word "community" is religious or neighborhood communities who collectively invest in each other's lives. But I don't expect other _Less Wrong_ users to help me move or bring me food when I'm sick or watch my hypothetical children, or for me to do those things for them. And there _are_ in-person "rationalist" communities (_e.g._, in Berkeley/Oakland) that do these things, and there _is_ such a thing as freeloading on the efforts of people who build those communities, and a lot of those people also have accounts on this website. But it's not clear how arguing about ideas on the website makes one a member of a "community" that extends beyond those arguments. _Reply!_

> You took the time to read the post, but you won't write a "quick" clarifying question because you're worried about wasting your time, and you think you have little to gain by understanding the content, so you’re depending on commenters like Said to do the job?

Is this not itself an expression of implied contempt for Dai's reluctance to ask clarifying questions? _Reply!_

> How do you know [that if you "discourage low-effort criticism, you’ll just get less criticism not better criticism"]? Have you gathered data on this topic?

I find it implausible that there are people able and willing to contribute high-effort criticism, who don't do so because of the presence of low-effort criticism. As a frequent high-effort critic myself, I just can't empathize with that at all. I don't have data on this, but [you probably don't, either](https://slatestarcodex.com/2014/08/14/beware-isolated-demands-for-rigor/). If you have data to share, I'd be happy to discuss it. _Reply!_

> why can't weak and uninteresting posts can be ignored or engaged with by a charitable volunteer as a teacher might respond to a student in order to develop their capabilities?

Because, as an author, I don't _want_ my readers to patronizingly volunteer to be my teacher in order to develop my capabilities. I want to know what my readers _actually think about my work_. _Reply!_


https://www.greaterwrong.com/posts/98sCTsGJZ77WgQ6nE/banning-said-achmiz-and-broader-thoughts-on-moderation/comment/GjtZY7pg9LRB2mwMi
> There are selection effects on who stays in the community under these conditions.
Indeed. For example, if a community selects for phonies who want people to lie to them in order to protect their feelings, and selects against people who want to have real, honest conversations, then you end up with a community full of phonies. 

---

> I would appreciate some courtesy[3] to keep discussion to the principles and decision-level instead of critiques of my personal behavior, as indeed much of the cost of moderation is measured in having any moderation-adjacent action be torn apart and be requested to be justified or defended.

No, fuck you—first of all, you didn't offer Said that courtesy. But also, I don't think Said deserves that courtesy, either.

And also, your comments to Alicorn revealed that there is a personal angle here—that's evidence that I have to update one

Yes, you are insane

I can't honestly keep it to the "principles" level, because that reinforces the idea that this decision is being made on the basis of principles, which I don't think it is. You don't get to claim to be a benevolent dictator and ask for that courtesy!!

In the don't-delegate-anythign post, Habryka complains about teams that try to make themselves indispensible by squatting on a key resource—but that's exactly what he's doing

-----

https://www.lesswrong.com/posts/98sCTsGJZ77WgQ6nE/banning-said-achmiz-and-broader-thoughts-on-moderation?commentId=Cz8nB3kJwdmqacwDf
>  no author complaints were load-bearing for this banning decision. I would make the same decision even if no prominent authors had complained.

the "non-load-bearing" excuse again: he claims that author complaints aren't load bearing, that's why he articulated a model—but models are supposed to make predictions! Lack of credible author threats to leave are evidence against the sneer club threat model!

This is a microcosm of why "non-load-bearing" is a trick/excuse: if it wasn't relevant to your argument in some way, you wouldn't have included it—you included it because you thought it had _some_ bearing

Ben Pace claims, "I also reject your characterization that we're intentionally sacrificing epistemic standards to get back good authors." https://www.lesswrong.com/posts/98sCTsGJZ77WgQ6nE/banning-said-achmiz-and-broader-thoughts-on-moderation?commentId=sx6AKQ9fNceTFS42F

-----

It's worse than fraud, competent fraudsters study the thing they're supposed to be imitating. This is sim-level-4, a copy of a copy of Eld Rationality

----

The thing Said was telling Spiracular was (not in these words), you should be more curious about modeling the views of the people you disagree with!!! This proves that the behavior is about ego defense, not about anti-strawmanning epistemology

----

If an author doesn't reply to comments, readers who happen to notice this will do a Bayesian update on their beliefs about the author based on that evidence in the context of their prior information. Maybe it's a small update, maybe it's a big one. Maybe its content is "The author is too busy to waste time on the comment section", maybe its content is "The author is a phony who can't defend their ideas." But whatever update the reader makes, it _can't_ be determined by site norms, because site norms can't make a hypothesis about the author _become true_.

-----

In an unrelated discussion—
"And, at the same time, it’s not necessarily (and, indeed, not likely to be) worth your time to engage with all of your critics, regardless of how many “rules” they did or did not break."
https://www.lesswrong.com/posts/FrR78Wy6s79keSuDe/actually-personal-attacks-after-object-level-arguments-is-a

----

stewardship duties— https://www.goodthoughts.blog/p/anti-ai-ideology-enforced-at-rphilosophy

---

Habryka talks about "gaslighting" about subtext, but gaslighting about text (the "flag") is much worse

-----

> one of the best things about lesswrongian rationalist culture is that unlike most of contemporary intellectual culture there is a norm of adversarial sparring outside of constrained occasional formalities (such as reviews on academic papers). if you make flawed or sloppy reasoning chains, you will be torn apart and forced to either "lose" or rise to a higher standard, at least if there's someone smart enough around who engages you.

> this doesn't seem to be the case much elsewhere, even among the intellectual elite, and discourse tends to either be too polite or passive or else tribal. it's common for respected scientists, technocrats, publication outlets, etc, to output malformed and confused reasoning chains that would be torn to shreds on Lesswrong.

https://x.com/repligate/status/1980238106818400385

-----

I had thought of Tsvi B-T as someone being disagreeable and not getting punished for it (and therefore on the "good" team of people who understand that disagreeableness is useful), but then he did the Duncan deflection at Wei Dai

----

Habryka hates delegation because he thinks teams and orgs will squat on key resources, but he's squatting on the brand and centrality built up from LW1

In Wei Dai's Nov. 2025 complaint (same thread as https://www.greaterwrong.com/posts/HbkNAyAoa4gCnuzwa/wei-dai-s-shortform/comment/3EGxCndmhBR3Fnix8 ; I'm not getting the exact comment link now), he talks about how LW is his forum and people don't like it should go elsewere;

but he didn't get that position because he's such an awesome forum administrator; he got it because of Anna's "The importance of a single locus" (and I expect Anna and Vaniver should see this if it's explained to them)

In the same thread he spends a lot of wordcount on Wei Dai's word choice of "common sense", but ignores the substance

-----

Elizabeth and Ray and the 109  see the value of Wentworth, evidence for the "Bay Area status ingroup" theory (Wentworth has agent-foundations chops, but as far as casual comments go, he and Achmiz are basically the same guy ... Wentworth does a little more corrupt softening)
https://www.lesswrong.com/posts/tv6KfHitijSyKCr6v/elizabeth-s-shortform?commentId=wLFzsALiPHbhFM85E


I strong-downvoted (but weak agree-upvoted) and put a too-sneering react on https://www.lesswrong.com/posts/2gGdPfw8fpEno9H4Y/the-ai-2027-report-is-not-backed-up-by-evidence?commentId=d6HEduF4Q94ALDBxy ... then I thought maybe I should leave an explanatory comment (because otherwise Habyrka will infer that the strong-downvote came from me due to its conjunction with the react), and explaining my thinking makes it better feedback, then I decided against the comment, because Habryka counts comments as a cost, rather than information


> One thing is sure, the path that leads to sanity and survival doesn't start with lies or with reasoning by Appeal to (Internal) Consequences.
https://twitter.com/ESYudkowsky/status/1743522277835333865
