## Conflict Theory of Bounded Distrust

Scott Alexander [once wrote about the difference between](https://slatestarcodex.com/2018/01/24/conflict-vs-mistake/) "mistake theorists" who treat politics as an engineering discipline (a symmetrical collaboration in which everyone ultimately just wants [the best ideas to win](https://slatestarcodex.com/2017/03/24/guided-by-the-beauty-of-our-weapons/)) and "conflict theorists" who treat politics as war (an asymmetrical conflict between sides with fundamentally different interests). Essentially, "[m]istake theorists naturally think conflict theorists are _making a mistake_"; "[c]onflict theorists naturally think mistake theorists are _the enemy in their conflict_."

More recently, Alexander [considered the phenomenon of "bounded distrust"](https://astralcodexten.substack.com/p/bounded-distrust): science and media authorities aren't completely honest, but are only willing to bend the truth so far, and can be trusted on the things they wouldn't lie about. Fox News wants to fuel xenophobia, but they wouldn't make up a terrorist attack out of whole cloth; liberal academics want to combat xenophobia, but they wouldn't outright fabricate crime statistics.

Alexander explains that savvy people who can figure out what kinds of dishonesty an authority will engage in, end up mostly trusting the authority, whereas clueless people become more distrustful. _Sufficiently_ savvy people end up inhabiting a mental universe where the authority _is_ trustworthy, as when Dan Quayle denied that characterizing tax increases as "revenue enhancements" constituted fooling the public—because "no one was fooled".

Alexander concludes with a characteristically mistake-theoretic plea for mutual understanding:

> The savvy people need to realize that the clueless people aren't _always_ paranoid, just less experienced than they are at dealing with a hostile environment that lies to them all the time.
>
> And the clueless people need to realize that the savvy people aren't _always_ gullible, just more optimistic about their ability to extract signal from same.

But "a hostile environment that lies to them all the time" is exactly the kind of situation where we would expect a conflict theory to be correct and mistake theories to be wrong!—or at least very incomplete. To speak as if the savvy merely have more skills to extract signal from a "naturally" occurring source of lies, obscures the critical question of _what all the lying is for_.

In [a paper on "the logic of indirect speech"](https://www.pnas.org/content/105/3/833), Pinker, Nowak, and Lee give the example of a pulled-over motorist telling a police officer, "Gee, officer, is there some way we could take care of the ticket here?"

This is, of course, a bribery attempt. The reason the driver doesn't just _say_ that ("Can I bribe you into not giving me a ticket?"), is because the driver doesn't know whether this is a corrupt police officer that accepts bribes, or an honest officer who will charge the driver with attempted bribery. The [indirect language](https://en.wikipedia.org/wiki/Plausible_deniability) lets the driver communicate to the corrupt cop (in the possible world where this cop is corrupt), without being arrested by the honest cop who doesn't think he can make an attempted-bribery charge stick in court on the evidence of such vague language (in the possible world where this cop is honest).

We need a conflict theory to understand this type of situation. Someone who assumed that all police officers had the same utility function would be fundamentally out of touch with reality: it's not that the corrupt cops are just "savvier", better able to "extract signal" from the driver's speech. The honest cops can probably do that, too. Rather, corrupt and honest cops are _trying to do different things_, and the driver's speech is optimized to help the corrupt cops in a way that honest cops can't interfere with (because the honest cops' objective requires working with a court system that _is_ less savvy).

This kind of analysis carries over to Alexander's discussion of government lies—maybe even isomorphically. When a government denies tax increases but announces "revenue enhancements", and supporters of the regime effortlessly know what they mean, while dissidents consider it a lie, it's not that regime supporters are just savvier. The dissidents can probably figure it out, too. Rather, regime supporters and dissidents are _trying to do different things_. Dissidents want to [create common knowledge of the regime's shortcomings](https://www.lesswrong.com/posts/9QxnfMYccz9QRgZ5z/the-costly-coordination-mechanism-of-common-knowledge#Dictators_and_freedom_of_speech): in order to organize a revolt, it's not enough for everyone to hate the government; everyone has to _know_ that everyone else hates the government in order to confidently act in unison, rather than fear being crushed as an individual. The regime's proclamations are optimized to communicate to its supporters in a way that doesn't give moral support to the dissident cause (because the dissidents' objective requires common knowledge, not just savvy individual knowledge).

This kind of analysis is about behavior, information, and the incentives that shape them. Conscious subjectivity, or any awareness of the game dynamics, are irrelevant. In the conscious minds of regime supporters, "no one was fooled", because if _you_ were fooled, then [you aren't anyone](https://thezvi.wordpress.com/2019/07/02/everybody-knows/): failing to be [complicit](https://slatestarcodex.com/2017/10/23/kolmogorov-complicity-and-the-parable-of-lightning/) with the reigning Power's law would be as insane as trying to defy the law of gravity.

Conversely, if blindness to Power has the same input–output behavior as conscious service to Power, then opponents of the reigning Power have no reason to care about the distinction. In the same way, [when a predator firefly sends the mating signal of its prey species](https://www.lesswrong.com/posts/YptSN8riyXJjJ8Qp8/maybe-lying-can-t-exist), we consider it _deception_, even if the predator is acting on instinct and can't consciously ["intend"](https://www.lesswrong.com/posts/sXHQ9R5tahiaXEZhR/algorithmic-intent-a-hansonian-generalized-anti-zombie) to deceive.

Thus, supporters of the regime naturally think dissidents are _making a mistake_; dissidents naturally think regime supporters are _the enemy in their conflict_.
