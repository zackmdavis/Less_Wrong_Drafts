## Conflict Theory of Bounded Distrust

Scott Alexander [once wrote about the difference between](https://slatestarcodex.com/2018/01/24/conflict-vs-mistake/) "mistake theorists" who treat politics as an engineering discipline (a symmetrical collaboration in which everyone ultimately just wants [the best ideas to win](https://slatestarcodex.com/2017/03/24/guided-by-the-beauty-of-our-weapons/)) and "conflict theorists" who treat politics as war (an asymmetrical conflict between sides with fundamentally different interests). Crucially, "[m]istake theorists naturally think conflict theorists are _making a mistake_"; "[c]onflict theorists naturally think mistake theorists are _the enemy in their conflict_."

More recently, Alexander [considered the phenomenon of "bounded distrust"](https://astralcodexten.substack.com/p/bounded-distrust): science and media authorities aren't completely honest, but are only willing to bend the truth so far, and can be trusted on the things they wouldn't lie about. Fox News wants to fuel xenophobia, but they wouldn't make up a terrorist attack out of whole cloth; liberal academics want to combat xenophobia, but they wouldn't outright fabricate crime statistics.

Alexander explains that savvy people who can figure out what kinds of dishonesty an authority will engage in, end up mostly trusting the authority, whereas clueless people become more distrustful. _Sufficiently_ savvy people end up inhabiting a mental universe where the authority _is_ trustworthy, as when Dan Quayle denied that characterizing tax increases as "revenue enhancements" constituted fooling the public—because "no one was fooled".

Alexander concludes with a characteristically mistake-theoretic plea for mutual understanding:

> The savvy people need to realize that the clueless people aren't _always_ paranoid, just less experienced than they are at dealing with a hostile environment that lies to them all the time.
>
> And the clueless people need to realize that the savvy people aren't _always_ gullible, just more optimistic about their ability to extract signal from same.

But "a hostile environment that lies to them all the time" is _exactly_ the kind of situation where we would expect a conflict theory to be correct and mistake theories to be wrong!—or at least very incomplete. To speak as if the savvy merely have more skills to extract signal from a "naturally" occurring source of lies, obscures the critical question of _what all the lying is for_.

In [a paper on "the logic of indirect speech"](https://www.pnas.org/content/105/3/833), Pinker, Nowak, and Lee give the example of a pulled-over motorist telling a police officer, "Gee, officer, is there some way we could take care of the ticket here?"

This is, of course, a bribery attempt. The reason the driver doesn't just _say_ that ("Can I bribe you into not giving me a ticket?"), is because the driver doesn't know whether this is a corrupt police officer that accepts bribes, or an honest officer who will charge the driver with attempted bribery. The indirect, plausibly deniable language lets the driver communicate to corrupt cops, without being arrested by honest cops who don't think they can make an attempted-bribery charge stick in court on the evidence of such vague language.

We need a conflict theory to understand this type of situation. Someone who assumed that all police officers had the same utility function would be fundamentally out of touch with reality: it's not that the corrupt cops are just "savvier", better able to "extract signal" from the driver's speech. Rather, corrupt and honest cops are _trying to do different things_, and the driver's [technically-not-lies](https://www.lesswrong.com/posts/MN4NRkMw7ggt9587K/firming-up-not-lying-around-its-edge-cases-is-less-broadly) are optimized to help the corrupt cops in a way that honest cops can't interfere with (because the honest cops' objective requires working with a court system that _is_ less savvy).

This kind of analysis carries over to Alexander's discussion of government lies—maybe even isomorphically.

[TODO—
 * savvy regime supporters quietly try to decode what official pronouncements means, but dissidents are trying to do a different thing—they want create common knowledge so they can topple or reform the regime
 * the picture is basically the same, even if no one is consciously "lying"; Dan Quayle's incentives and input–output behavior are the same, whether or not he "honestly" believe that no one is fooled, or he understands the simulacrum game and is doing it consciously
  * regime supporters think dissidents are _making a mistake_; dissidents think regime supporters are _the enemy in their conflict_
]
