## Assume Bad Faith

I've been trying to avoid the terms "good faith" and "bad faith". I'm suspicious that most people who have picked up the phrase "bad faith" from hearing it used, don't actually know what it means—and maybe, that the thing it does mean doesn't [carve reality at the joints](https://www.lesswrong.com/posts/esRZaPXSHgWzyB2NL/where-to-draw-the-boundaries).

People get very touchy about bad faith accusations: they think that you should assume good faith, but that if you've determined someone is in bad faith, you shouldn't even be talking to them, that you need to exile them.

What does "bad faith" _mean_, though? It doesn't mean "with ill intent." [Following _Wikipedia_](https://en.wikipedia.org/wiki/Bad_faith), bad faith is "a sustained form of deception which consists of entertaining or pretending to entertain one set of feelings while acting as if influenced by another." The great encyclopedia goes on to provide examples: the solider who waves a flag of surrender but then fires when the enemy comes out of their trenches, the attorney who prosecutes a case she knows to be false, the representative of a company facing a labor dispute who comes to the negotiating table with no intent of compromising.

That is, bad faith is when someone's apparent reasons for doing something aren't the same as the real reasons. This is distinct from malign intent. The uniformed solider who shoots you without pretending to surrender is acting in good faith, because what you see is what you get: the man whose clothes indicate that his job is to try to kill you is, in fact, trying to kill you.

The policy of assuming good faith (and mercilessly punishing rare cases of bad faith when detected) would make sense if you lived in an honest world where what you see generally is what you get (and you wanted to keep it that way), a world where the possibility of hidden motives in everyday life wasn't a significant consideration.

On the contrary, however, I think hidden motives in everyday life are ubiquitous. As evolved creatures, we're designed to believe as it benefitted our ancestors to believe. As social animals in particular, the most beneficial belief isn't always the true one, because tricking your conspecifics into adopting a map that implies that they should benefit you is sometimes more valuable than possessing the map that reflects the territory, and the most persuasive lie is the one you believe yourself. [A world where people were straightforwardly trying to inform each other would look incredibly alien to us.](https://www.lesswrong.com/posts/h2Hk2c2Gp5sY4abQh/lack-of-social-grace-is-an-epistemic-virtue)

But if that's the case (and you shouldn't take my word for it), being too touchy about bad faith accusations seems maladaptive. If it's normal for people's stated reasons to not be the same as the real reasons, it shouldn't be beyond the pale to think that of some particular person, nor should it necessarily entail cutting the "bad faith actor" out of public life—if only because, applied consistently, there would be no one left. Why would you trust anyone so highly as to think they never have a hidden agenda? Why would you trust yourself?

The conviction that bad faith is unusual contributes to a warped view of the world


In particular, people seem to believe that persistent good faith disagreements are an ordinary phenomenon.

that we can both be honest seekers of truth, and still end up persistently disagreeing


https://www.lesswrong.com/posts/sXHQ9R5tahiaXEZhR/algorithmic-intent-a-hansonian-generalized-anti-zombie
 * Actual good faith disagreements (where you're both just trying to get to the truth, and there are no other hidden motives, no _something else_ going on) tend not to persist! https://www.lesswrong.com/posts/iThwqe3yPog56ytyq/aiming-for-convergence-is-like-discouraging-betting
 * Example 1: I ask you if it's going to rain. You say, "Yes, I read the weather report". I _immediately_ replace my belief with yours.
 * Example 2: We're both trying to calculate something, and we get different answers. If I think we're both equally good calculators, I don't feel particularly attached to the belief that my answer is right.
 * Most disagreements of note—most disagreements that people _care about_—don't look like this, from which we can infer that there is "something else" going on than just trying to get the facts
 * Even if everything you say is true, that doesn't save you from "something else" going on—you're probably selecting the facts to advance your interests
 * But admitting that you're doing that isn't part of the game! The universal practice is to come up with arguments to persuade the other guy why it's in _his_ interests to do the thing that you want
 * Inferential distance isn't a compelling explanation: in the case of the disagreeing mathematicians, you tend to assign a large probability that the other guy is right, even if you don't see how they got it.
 * Some might say: bad faith is about "intent", an "honest bias" isn't bad faith
 * From the standpoint of information transfer, the difference between bias and deception is _uninteresting_. If the apple is green, and you tell me it's red and I believe you, I end up with false beliefs about the apple. It _doesn't matter_ whether you said it was red because you were lying or because you're wearing rose-colored glasses; the input–output function is the same
 * At best, conscious deception is worse than bias because it offers much more resistance: someone who's merely biased will fold when presented with a compelling argument, someone's who's consciously lying will _keep_ lying until you catch them red-handed in front of an audience with power over them
 * Given that there's usually "something else" going on, how do we go on?
 * Two strategies: stick to the object-level arguments, and full-contact psychoanalysis.
 * In most cases, I _prefer_ to stick to the object-level: just engage with the text of what people said, without addressing what you think their angle is in saying it.
 * This is the main benefit of "assume good faith" norms, but a crucial difference is that you should _not_ be assuming good faith, and you should have to pretend that you are, either: just—address the text! It's not that you shouldn't suspect hidden motives, it's that those are _off-topic_.
 * The other alternative is full-on cards-on-the-table conflict-theory psychologizing. Done well, it looks like a negotiation.
 * Ironically, the strategy that corresponds to "assume good faith" is actually less honest than admitting that the disagreement is actually a negotiation
