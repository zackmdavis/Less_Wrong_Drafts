## On the Contrary, Steelmanning Is Normal; ITT-Passing Is Niche

Rob Bensinger argues that ["ITT-passing and civility are good; 'charity' is bad; steelmanning is niche"](https://www.lesswrong.com/posts/MdZyLnLHuaHrCskjy/itt-passing-and-civility-are-good-charity-is-bad).

The ITT—[Ideological Turing Test](https://www.econlib.org/archives/2011/06/the_ideological.html)—is an exercise in which one attempts to present one's opponent's views as persuasively as the opponent themselves can, coined in analogy to the Turing Test for distinguishing between humans and intelligent machines. (An AI that can pass as human must presumably possess human-like understanding; an opponent of an idea that can pass as an advocate for it presumably must possess an advocate's understanding.)

"Steelmanning" refers to the practice of addressing a stronger version of an interlocutor's argument, coined in disanalogy to ["strawmanning"](https://en.wikipedia.org/wiki/Straw_man), the crime of addressing a weaker version of an interlocutor's argument in the hopes of fooling an audience (or oneself) that the original argument has been rebutted.

Bensinger describes steelmanning as "a useful niche skill", but thinks it isn't "a standard thing you bring out in most arguments." Instead, he writes, discussions should be structured around object-level learning, trying to pass each other's Ideological Turing Test, or trying resolve cruxes.

I think Bensinger has it backwards: the Ideological Turing Test is a useful niche skill, but it doesn't belong on the same list as object-level learning and resolving cruxes, as things to structure a discussion around.

The ITT is a test of your ability to model someone else's models of some real-world phenomena of interest. This is niche because 


I couldn't pass an ITT for advocates of Islam or extrasensory perception. On the one hand, this does represent a distinct deficit in my ability to model what the advocates of these ideas are thinking. On the other hand, this seems ... basically fine? I already have strong reasons to doubt the existence of [ontologically fundamental mental entities](https://www.lesswrong.com/posts/u6JzcFtPGiznFgDxP/excluding-the-supernatural).



 * The basic issue is that "modeling what another person thinks about reality" is usually less interesting than just directly modeling reality.
 * I couldn't pass an ITT for Islam or extrasensory perception, but that seems basically fine; I already have reasons 


 * Another way to think of it: as a [selfish](https://www.lesswrong.com/posts/vfjptEJ2oahLqRyZz/justice-cherryl) accuracy-maxxer, when would I want to try to pass someone's ITT, and when would I want someone to pass my ITT?
 * In the outbound direction, it's not clear why I care what someone else thinks
 * In the inbound direction, it's not clear why I care that someone else knows how I think. I don't want to demand that someone pass my ITT before they offer criticism, because then I might miss out on useful criticism!
 * If I don't (ideally) want it, presumably the other person doesn't, either, so why would we do it?

 * I agree that ITT-passing is desirable; the basic case for its desirability is that it's a check that you and your interlocutor are talking about the same thing rather than you strawmanning them.
 * These are cases when I do want to offer "Can you pass my ITT"—when I don't think good faith is present
 * I also agree (as Bensinger quotes Yudkowsky) that there's a failure mode of steelmanning-as-weakmanning
 * _After_ engaging with someone, you should do a better job of passing their ITT (and it would be worrying if you couldn't), but that doesn't mean ITT-passing should be the focus of the discussion, contrasted to good old-fashioned debate

 * In contrast, steelmanning is oriented towards improving arguments 

 * Think about trying to write computer programs instead of building arguments. If someone says, "Hey, you should do it this way"; adopting it with improvements is a completely ordinary thing

### A Historical Note

 * http://web.archive.org/web/20100328161823/http://www.acceleratingfuture.com/steven/?p=155

> If you’re interested in being on the right side of disputes, you will refute your opponents’ arguments. But if you’re interested in producing truth, you will fix your opponents’ arguments for them.
>
> To win, you must fight not only the creature you encounter; you must fight the most horrible thing that can be constructed from its corpse.

https://www.lesswrong.com/posts/pkaagE6LAsGummWNv/contra-yudkowsky-on-epistemic-conduct-for-author-criticism
https://www.lesswrong.com/posts/2jp98zdLo898qExrr/hug-the-query

