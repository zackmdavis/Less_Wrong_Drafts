## Comment on "Death and the Gorgon"

_(some plot spoilers)_

There's something distinctly uncomfortable about reading Greg Egan in the 2020s. Besides telling gripping tales with insightful commentary on true nature of mind and existence, Egan stories written in the 1990s and set in the twenty-first century excelled at speculative worldbuilding, imagining what technological wonders might exist in the decades to come and how Society might adapt to them.

In contrast, "Death and the Gorgon", published in the January/February 2024 issue of _Asimov's_, feels like it's set [twenty minutes into the future](https://tvtropes.org/pmwiki/pmwiki.php/Main/TwentyMinutesIntoTheFuture). The technologies on display are an AI assistant for police officers (capable of performing research tasks and carrying on conversation) and real-time synthetic avatars (good enough to pass as a video call with a real person). When these kinds of products showed up in "'90s Egan"—I think of Worth's "pharm" custom drug dispenser in _Distress_ (1995) or Maria's "mask" for screening spam calls in _Permutation City_ (1994)—it was part of the background setting of a more technologically advanced world than our own.

Reading "Gorgon" in 2024, not only do the depicted capabilities seem less out of reach (our language model assistants and deepfakes aren't quite there yet, but don't seem too far off), but their literary function has changed: much of the moral of "Gorgon" seems to be to chide people in the real world who are overly impressed by ChatGPT. Reality and Greg Egan are starting to meet in the middle.

Our story features Beth, a standard-issue Greg Egan protagonist[^egan-protagonist] as a small-town Colorado sherriff investigating the suspicious destruction of a cryonics vault in an old mine: a naturally occuring cave-in seems unlikely, but it's not clear who would have the motive to thaw (murder?) a hundred frozen heads.

[^egan-protagonist]: Some people say that Greg Egan is bad at characterization. I think he just specializes in portraying _reasonable_ people, who don't have grotesque personality flaws to be the subject of "characterization."

Graciously tolerating the antics of her deputy, who is obsessed with the department's trial version of (what is essentially) ChatGPT-for-law-enforcement, Beth proceeds to interview the next of kin, searching for a motive. She discovers that many of the recently preserved were beneficiaries of a lottery for terminal patients in which the prize was free cyronic suspension. The lottery is run by OG—"Optimized Giving"—a charitable group concerned with risks affecting the future of humanity. As the investigation unfolds, Beth and a colleague at the FBI begin to suspect that the lottery is a front for a creative organized crime scheme: OG is recruiting terminal patients to act as assassins, carrying out hits in exchange for "winning" the lottery. (After which another mafia group destroyed the cryonics vault as retaliation.) Intrigue, action, and a cautionary moral ensue as our heroes make use of ChatGPT-for-law-enforcement to prove their theory and catch OG red-handed before more people get hurt.

-----

So, cards on the table: this story spends a lot of wordcount satirizing a subculture that, unfortunately, I don't think I can credibly claim not to be a part of. "Optimized Giving" is clearly a spoof on the longtermist wing of Effective Altruism—and if I'm not happy about how the "Effective Altruism" brand ate my beloved rationalism over the 2010s, I don't think anyone would deny the contiguous memetic legacy involving many of the same people. ([Human subcultures are nested fractally](https://xkcd.com/1095/); for the purposes of reviewing the story, it would benefit no one for me to to insist Egan isn't talking about me and my people, even if, from _within_ the subculture, it looks like the OpenPhil people and the MIRI people and ... _&c._ are all totally different and in fact hate each other's guts.)

I don't want to be defensive, because I'm _not_ loyal to the subculture, its leaders, or its institutions. In the story, Beth talks to a professor—think [Émile Torres](https://en.wikipedia.org/wiki/%C3%89mile_P._Torres#Transhumanism,_longtermism,_and_effective_altruism) as a standard-issue Greg Egan character—who studies "apostates" from OG who are angry about "the hubris, the deception, and the waste of money." That resonated with me a lot: I have a long [dumb](http://unremediatedgender.space/2023/Jul/blanchards-dangerous-idea-and-the-plight-of-the-lucid-crossdreamer/) [story](http://unremediatedgender.space/2023/Jul/a-hill-of-validity-in-defense-of-meaning/) [to tell](http://unremediatedgender.space/2023/Dec/if-clarity-seems-like-death-to-them/) [about hubris and deception](http://unremediatedgender.space/2024/Mar/agreeing-with-stalin-in-ways-that-exhibit-generally-rationalist-principles/), and the corrupting forces of money are probably a big part of the explanation for [the rise and perversion of Effective Altruism](http://benjaminrosshoffman.com/effective-altruism-is-self-recommending/).

So if my commentary on Egan's satire contains some criticism, it's absolutely _not_ because I think my ingroup is beyond reproach and doesn't deserve to satirized. They (we) absolutely do. (I took joy in including a similar caricature in [one of my own stories](http://unremediatedgender.space/2023/Oct/fake-deeply/).) But if Egan's satire doesn't quite hit the mark of explaining exactly why the group is bad, it's not an act of partisan loyalty for me to contribute my nuanced explanation of what I think it gets right and what it gets wrong. I'm not carrying water for the movement; it's just a topic that I happen to have a lot of information about.

Without calling it a fair portrayal of its real-world analogue, the OG of "Gorgon" isn't a strawman conjured out of thin air; the correspondences are clear. When our heroine suspiciously observes that these _soi-disant_ world-savers don't seem to be spending anything on climate change and the Émile Torres–analogue tells her that OG don't regard it as an existential threat, [this is also true of real-world EA](https://forum.effectivealtruism.org/posts/eJPjSZKyT4tcSGfFk/climate-change-is-in-general-not-an-existential-risk). When the Torres-analogue says that "OG view any delay in spreading humanity at as close to light-speed as possible as the equivalent of murdering all the people who won't have a chance to exist in the future," the argument isn't a fictional parody; it's a somewhat uncharitably phrased summary of Nick Bostrom's ["Astronomical Waste: The Opportunity Cost of Delayed Technological Development"](https://nickbostrom.com/papers/astronomical-waste/). When the narrator describes some web forums as "interspers[ing] all their actual debunking of logical fallacies with much more tendentious claims, wrapped in cloaks of faux-objectivity" and being "especially prone to an abuse of probabilistic methods, where they pretended they could quantify both the likelihood and the potential harm for various implausible scenarios, and then treated the results of their calculations—built on numbers they'd plucked out of the air—as an unimpeachable basis for action", one could quibble with the disparaging description of subjective probability, but you can tell which real-world forums are being talked about.

The cryonics-as-murder-payment lottery scheme is fictional, of course, but I'm inclined to read it as artistically-licensed commentary on a certain strain of ends-justify-the-means thinking within EA. EA organizations don't take from the mob for facilitating contract killings, but they _did_ take money from [the largest financial fraud in history](https://en.wikipedia.org/wiki/FTX), [which was explicitly founded as a means to make money for EA](https://thezvi.wordpress.com/2023/10/24/book-review-going-infinite/). (One could point out that the charitable beneficiaries of Sam Bankman-Fried's largesse didn't know that FTX wasn't legitimate, but we have to assume that the same is true of OG in the story: only a few insiders would be running the contract murder operation, not the rank-and-file believers.)

While the depiction of OG in the story clearly shows familiarity with the source material, the satire feels lacking insofar as it relies too much on mere dismissal rather than presenting clear counterarguments. The effect of OG-related web forums on a vulnerable teenager are described thus:

> Super-intelligent AIs conquering the world; the whole Universe turning out to be a simulation; humanity annihilated by aliens because we failed to colonize the galaxy in time. Even if it was all just stale clichés from fifty-year-old science fiction, a bright teenager like Anna could have found some entertainment value analyzing the possibilities rigorously and puncturing the forums' credulous consensus. But while she'd started out healthily skeptical, some combination of in-forum peer pressure, the phony gravitas of trillions of future deaths averted, and the corrosive effect of an endless barrage of inane slogans pimped up as profound insights—all taking the form "X is the mind-killer," where X was pretty much anything that might challenge the delusions of the cult—seemed to have worn down her resistance in the end.

I absolutely agree that healthy skepticism is critical when evaluating ideas and that in-forum peer pressure and the gravitas of a cause (for any given set of peers and any given cause) are troubling sources of potential bias—and that just because a group pays lip service to the value of healthy skepticism and the dangers of peer pressure and gravitas, doesn't mean the group's culture isn't still falling prey to the usual dysfunctions of groupthink. (As the inane slogan goes, ["Every cause wants to be a cult."](https://www.lesswrong.com/posts/yEjaj7PWacno5EvWa/every-cause-wants-to-be-a-cult))

That being said, however, ideas ultimately need to be judged on their merits, and the narration in this passage isn't giving the reader any counterarguments to the ideas being alluded to. ("These are stale clichés from fifty-year-old science fiction" isn't a counterargument; as Egan should know, science fiction authors having written about an idea does not make the idea false.) The clause about the whole Universe turning out to be a simulation is likely a reference to Bostrom's [simulation arugment](https://simulation-argument.com/simulation/), which is a disjunctive, conditional claim: _given_ certain computationalist assumptions in the philosophy of mind, then _if_ future civilization could run simulations of its ancestors, then _either_ they won't want to, _or_ we're probably in one of the simulations (because there are more simulated than "real" histories). The clause about humanity being annihilated by failing to colonize the galaxy in time is likely a reference to Robin Hanson _et al._'s [grabby aliens thesis](https://grabbyaliens.com/), that the Fermi paradox can be explained by a selection effect: there's a relatively narrow range of parameters in which we would see signs of an expanding alien civilization in our skies without already having been engulfed by them.

No doubt many important criticisms could be made of Bostrom's or Hanson's work.






The reference to humanity annihilated by aliens because we failed to colonize the galaxy in time is presumably 

[TODO—
 * What it gets wrong—
    * beliefs are cartoony: "any smart teenager could have disproven" ... I don't think this is true   
    * "on the epic struggle to make computers competent enough to help bring down the fools who believe that they’re going to be omnipotent"
    * But AI being powerful and misaligned is absolutely a real threat, as seen in ["Steve Fever"](https://www.technologyreview.com/2007/10/15/223446/steve-fever/) (2007) or ["Crystal Nights"](https://gregegan.net/MISC/CRYSTAL/Crystal.html). The polises in Disaspora absolutely could have glassed the fleshers if they wanted to
    * million light-year rope is actually a fine critique
]


[TODO—
  * This isn't Egan's first time making fun of "us", but I find the non-substantive mockery unfortunate.
  * I worry that this would be taken as defensiveness, but it's not—it would be lovely to have Greg Egan as a rival
]


-------

### Plot summary

 * cryonics vault collapses, our sherriff protagonist Beth is to investigate whether foul play
    * (all Greg Egan protagonists are basically the same person)
 * fair-minded discussion of cryonics with husband
 * interviewing family members, some of the heads won a lottery by "Optimized Giving"
 * (in reality, life insurance is affordable)
 * Beth's coworker obsessed with AI assistant Sherlock
 * leading theory: competing cryonics company??
 * one family statement claims lottery winner was pressured to die early
 * characterization of OG
     * "Some of them started out sounding like worthy causes, until you hit the strange last clause" p. 171
 * partner compares to Make-A-Wish Foundation, Beth notices that cryo lottery doesn't seem very "optimized"
 * talks to OG-ologist (Emile Torres role, but as a Greg Egan character)
 * "They don't seem to be spending anything on climate change." "OG consider that solved." (p. 174) Accurate!
 * Torres speculates that the lottery is just good PR
 * "What they’re angry about is the hubris, the deception, and the waste of money."
 * Sherlock turns up Anna
 * Beth follows Anna to Dallas, who ends up being followed by someone else, too; Beth intervenes when Anna pulls out a gun
 * It transpires that lottery winners have been witnesses or POIs of shootings
 * "OG are raising funds by selling the services of terminally ill assassins. Cleanskins, with no criminal record and no connection to the victim"
 * organized crime trigged the vault collapse, as revenge/incentives
 * plan to take over apostate accounts to be the next assassin, impersonating them with an LLM
 * partner pretends to be an apostate volunteer
 * at the meeting, he takes a syringe meant to shorten his time and secure his committment
 * syringe taking was on AI's advice
 * they write a criminology journal article 
 * "on the epic struggle to make computers competent enough to help bring down the fools who believe that they’re going to be omnipotent"

### Other Notes

 * snipe at LLMs on p. 185: "Sherlock had absolutely no conception of what a movie was"
 * plausibility question: is OG big enough such that there are a lot of terminally ill assassins? (most terminal patients are old, right?) I remember it being a big deal when Hal Finney died
 * fun names: ZonesOfOught, DarkCardinal, and BayesianBae  (realistic usernames) 
 * distrust of LLM decisions is well taken
 * "it had no real conception of what might happen if its words were acted on"—that part is correct! and it's an alignment problem!
 * "they need to drop the half-baked imitation of it being some kind of colleague"
 * cryonics-as-blood-money is a bit cartoony, but it's not vile slander, it rhymes with a certain strain of bloodless utilitarianism; these days, EA has billionaire support and doesn't need mob support, but back in the day, there was idle talk of life insurance suicide fraud, or Ziz's Uber-for-porn loophole idea; or SBF himself

## Egan's history of TESCREAL criticism

 * I don't want to seem too defensive, because I do hate you motherfuckers; I think I've been very clear about that in my memoir; and "Fake Deeply" also engages in some mockery
 * There totally are culty elements: if his impression was formed from https://www.scientificamerican.com/article/ai-safety-research-only-enables-the-dangers-of-runaway-superintelligence/ , I can see why he'd think that

 * But Egan's contempt doesn't hit the mark of exactly _why_ the scene deserves contempt, doesn't hit the good parts
 * he has a history of sniping at "us": Nate Caplan in Zendeghi, "Crystal Nights", snipe about the general intelligence theorem in Schild's Ladder
 * Torres and Gebru's TESCREAL is actually apt (EA/OG wasn't a thing at the time of the Zendeghi satire)
 * But risks of AIs not behaving as their creators intended is a real thing that Egan of course acknowledges (as in "Crystal Nights" or "Steve Fever")
 * The polises of Diaspora could have glassed the fleshers _if they wanted to_
 * I still want my Egan/Hanson collaboration

 * "Intelligence explosion microeconomics" isn't _goofy_, even if you disagree with it

 * I think I've flip-flopped on the satire of postmodernism in Terenesia: at first I was cold (while I was still a SJW), then I got it, now I'm not sure Egan is a fair critic
 * Cosma Shalizi is even worse: http://bactra.org/notebooks/nn-attention-and-transformers.html#cultists

 * compare to Chiang on blurry JPEGs?

https://firstmonday.org/ojs/index.php/fm/article/view/13636/11599 

https://twitter.com/gregeganSF/status/1727940487255138404
> Oh, I think they've noticed, but some of them still like the, err, "early, funny ones" that predate the cult and hence devote no time to mocking it.

 * I'll confess that I do treasure early Egan more than later Egan, but that's not the reason: it's that I'm not smart enough to appreciate them
 * Or is the fact that I'm saying "not smart enough" a shibboleth? Egan does not seem HBD-pilled

https://twitter.com/zackmdavis/status/1728850649012695136
> I still liked Zendegi & "Crystal Nights"! Books that mock my subculture can still be good on the merits! (I do find the contempt puzzling, though. What are the conditions that make mockery seem more appealing than a more tempered "I disagree with this group about this-and-such"?)

https://twitter.com/zackmdavis/status/1365534204075806720
> new @gregeganSF story is ... based?? (story-universe does not hew to (unrealistic) "universalist" intelligence-implies-nonselfishness assumption often seemingly validated in other Egan stories, somewhat abating my fanciful wish for a collaboration with @robinhanson)

https://twitter.com/robinhanson/status/1365662127504187396
> And he’s blocked me, not a good sign re collaboration

https://twitter.com/XiXiDu/status/1365675253976956928
> This made me wonder why I am not following him on Twitter so I checked out Egan's tweets and couldn't find even one opinion that's either controversial or which violates the mainstream consensus. A bunch of woke stuff though. In other words, just noise that's to be ignored.

https://twitter.com/zackmdavis/status/1365715251283464196
> Only if you're mindkilled by politics!! Knowing as much math and physics as Greg Egan is very time-consuming! Hypothetically, if we did live in a world where mainstream consensus on some less-strictly-technical topics were wrong, it shouldn't be his job to notice. 1/2
> Also, don't confuse late-20th-century-style environmentalist/human-rights liberalism with Twitter-era wokeness!! His Terenesia (1999) is very tough on postmodernism (in a way that I thought was too harsh when I read it in ~2008, but now, I get it) 2/2

> a bright teenager like Anna could have found some entertainment value analyzing the possibilities rigorously and puncturing the forums' credulous consensus.
I don't think this is true

https://twitter.com/teortaxesTex/status/1752469634173800710
> it's like treating two countries at war like a single political party because they're both populated by heliocentrists

Asimov's back issues: https://www.magzter.com/US/Penny-Publications-LLC/Asimovs-Science-Fiction/Fiction/

https://www.newyorker.com/culture/the-weekend-essay/why-ai-isnt-going-to-make-art

> it’s funny that Ted chiang wrote that short story / sermon about empathizing with parrots before looking for alien intelligence but doesn’t recognize the aliens that landed in his backyard
https://x.com/tszzl/status/1831066060646473732
