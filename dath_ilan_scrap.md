-------

[OUTLINE—
    * the race of dath ilani humans are called the "eliezera" in Word of God canon
   presenting an eliezera racial supremacy narrative. (It's still a racial supremacy narrative even if he doesn't _use the verbatim phrase_ "racial supremacy.")
     * Bluntly, this is not a culture that gives a shit about people being well-informed. This is a culture that has explicitly
         * In more detail: the algorithm that designed dath ilani Civilization is one that systematically favors plans that involve deception, over than plans that involve being honest.
         * This is not a normative claim or a generic slur that dath ilani are "evil" or "bad"; it's a positve claim about systematic deception. If you keep seeing plans for which social-deception-value exceeds claimed-social-benefit value, you should infer that the plans are being generated by a process that "values" (is optimizing for) deception, whether it's a person or a conscious mind.
         * Watsonian rationale: with smarter people, knowledge actually is dangerous. I'm more interested in a Doylist interpretation, that this reflects authoritarian tendencies in later Yudkowsky's thought.

You can, of course, make up a sensible [Watsonian](https://tvtropes.org/pmwiki/pmwiki.php/Main/WatsonianVersusDoylist) rationale for this. A world with much smarter people is more "volatile"; with more ways for criminals and terrorists to convert knowledge into danger, maybe you _need_ more censorship just to prevent Society from blowing itself up.

I'm more preoccupied by a [Doylistic](https://tvtropes.org/pmwiki/pmwiki.php/Main/WatsonianVersusDoylist) interpretation—that dath ilan's obsessive secret-Keeping reflects something deep about how the Yudkowsky of the current year relates to speech and information, in contrast to the Yudkowsky who wrote the Sequences. The Sequences had encouraged you—yes, _you_, the reader—to be as rational as possible. In contrast, the dath ilan mythos seems to portray advanced rationality as dangerous knowledge that people need to be protected from.

As another notable example of dath ilan hiding information for the alleged greater good, in Golarion, Keltham discovers that he's a sexual sadist, and deduces that Civilization has deliberately prevented him from realizing this, because there aren't enough corresponding masochists to go around in dath ilan. Having concepts for "sadism" and "masochism" as variations in human psychology would make sadists like Keltham sad about the desirable sexual experiences they'll never get to have, so Civilization arranges for them to _not be exposed to knowledge that would make them sad, because it would make them sad_ (!!).

What happens, I asked, to the occasional dath ilani free speech activists, with their eloquent manifestos arguing that Civilization would be better off coordinating on maps that reflect the territory, rather than coordinating to be a Keeper-managed zoo? (They _had_ to exist: in a medianworld centered on Yudkowsky, there are going to be a few weirdos who are +2.5 standard deviations on "speak the truth, even if your voice trembles" and −2.5 standard deivations on love of clever plots; this seems less weird than negative utilitarians, who were [established to exist](https://www.glowfic.com/replies/1789623#reply-1789623).) I _assumed_ they get dealt with somehow in the end (exiled from most cities? ... involuntarily cryopreserved?), but there had to be an interesting story about someone who starts out whistleblowing small lies (which Exception Handling allows; they think it's cute, and it's "priced in" to the game they're playing), and then just keeps _escalating and escalating and escalating_ until Governance decides to unperson him.

[...]

If we believe that [IQ research validates the "Jews are clever" stereotype](https://web.mit.edu/fustflum/documents/papers/AshkenaziIQ.jbiosocsci.pdf), I wondered if there's a distinct (albeit probably correlated) "enjoying deception" trait that validates the "Jews are sneaky" stereotype? If dath ilan is very high in this "sneakiness" trait (relative to Earth Jews), that would help explain all the conspiracies!

The existence of such a widespread sneakiness/"taste for deception" trait among the eliezera, in conjunction with their culture just not particularly valuing public knowledge (because they assume everything important is being handled by the Keepers), explains the recurring conspiracies and coverups, like the Ordinary Merrin Conspiracy, Exception Handling's fabrication of evidence for Sparashki being real, the sadism/masochism coverup, and [the village that deliberately teaches anti-redhead bigotry to children in order to test the robustness of dath ilan's general humanism indoctrination](https://www.lesswrong.com/posts/uyBeAN5jPEATMqKkX/lies-told-to-children-1).

I stress that this hypothesis _doesn't_ require dath ilani to be cartoon villains who hate knowledge and want people to be ignorant. Just that, as a result of the widespread sneakiness trait and their outsourcing information-process to the Keepers, in the course of trying to accomplish other things, plans-that-involve-conspiracies are often higher in their search ordering than plans-that-involve-keeping-people-informed.

I claimed that there was a hidden-core-of-rationality thing about a culture that values living in truth, that the dath ilani didn't have. In previous discussion of the Sparashki example, a user called lc had written, "If you see someone wearing an elf costume at work and conclude elves are real and make disastrous decisions based on that conclusion you are mentally deranged". And indeed, you would be mentally deranged if you did that _on Earth_, because we don't have an elves-are-real conspiracy on Earth.

In elves-are-real conspiracy-world, you (Whistleblower) see someone (Conspirator) wearing an elf costume at work and say, "Nice costume." They say, "What costume?" You say, "I see that you're dressed like an elf, but elves aren't real." They say, "What do you mean? Of course elves are real. I'm right here." You say, "You know exactly what I mean."

It would appear that there's a conflict between Conspirator (who wants to maintain a social reality in which they're an elf, because it's fun, and the conspiracy is sufficiently outlandish that it's assumed that no one is "really" being deceived) and Whistleblower (who wants default social reality to map to actual reality; make-believe is fine at a designated fandom convention which has designated boundaries, but let's be serious at work, where your coworkers are trying to make a living and haven't opted-in to this false social reality).

I was skeptical that a culture where people collude to maintain a fake social reality at their job in a hospital, and everyone else is expected to play along because it's fun, really has this living-in-truth thing. People play those social-reality games on Earth, too, and when _they_ say no one is being deceived, they're _definitely_ lying about that, and I doubted that the eliezera were actually built that differently.

"Natural History of Ashkenazi Intelligence"

(I was tempted to tag that as "epistemic status: low-confidence speculation", but that's _frequentist_ thinking—as if "Jews and gentiles are equally sneaky" were a "null hypothesis" that could only be rejected by data that would be sufficiently unlikely assuming that the null was true. Ha ha, that would be _crazy!_ Obviously, I should have a _prior_ on the effect size difference between the Jew and gentile sneakiness distributions, that can be updated as sneakiness data comes in. I think the mean of my prior distribution is at, like, _d_ ≈ 0.1? So it's not "low confidence"; it's "low confidence of the effect size being large enough to be of much practical significance".)

For context on why I have no sense of humor about this, on Earth (which _actually exists_, unlike dath ilan), when someone says "it's not lying, because no one _expected_ me to tell the truth in that situation", what's usually going on, [as Zvi Mowshowitz explains](https://thezvi.wordpress.com/2019/07/02/everybody-knows/), is that is that conspirators benefit from deceiving outsiders, and the claim that "everyone knows" is them lying to _themselves_ about the fact that they're lying.

(If _you_ got hurt by not knowing, well, it's not like anyone got hurt, because if you didn't know, then you weren't anyone.)

Okay, but if it were _actually true_ that everyone knew, what would be _function_ of saying the false thing? On dath ilan (if not in Earth boardrooms), I suppose the answer is "Because it's fun"? Okay, but what is the function of your brain giving out a "fun" reward in this context? It seems like at _some_ point, there has to be the expectation of _some_ cognitive system (although possibly not an entire "person") taking the signals literally.

That's why, when I _notice_ myself misrepresenting my actual beliefs or motivations because I think it's funny or rhetorically powerful (and it takes a special act of noticing; humans aren't built to be honest by default), I often take care to disclaim it immediately (as was observed in the message this is one a reply to), precisely because I _don't_ think that "everybody knows"; I'm not going to give up on humor or powerful rhetoric, but I'm also not going to delude myself into thinking it's "zero-calorie" (people who don't "get the joke" _are_ going to be misled, and I don't think it's unambigously "their fault" for not being able to read my "intent" to arbitrary precision)

But maybe dath ilan is sufficiently good at achieving common knowledge in large groups that they _can_ pull off a zero-calorie "everyone knows" conspiracy without damaging shared maps??

I'm still skeptical, especially given that we see them narratizing it as "not lying" (in the same words that corrupt executives on Earth use!), rather than _explicitly_ laying out the evopysch logic of sneakiness superstimuli, and the case that they know how to pull it off in a zero-calorie (trivial damage to shared maps) way.

In general, I think that "it's not lying because no one expected the truth" is something you would say as part of an attempted nearest-unblocked-strategy end run around a deontological constraint against "lying" (https://www.lesswrong.com/posts/MN4NRkMw7ggt9587K/firming-up-not-lying-around-its-edge-cases-is-less-broadly); I don't think it's something you would say if you _actually cared_ about shared maps being accurate

What I see on Earth (which, again, _actually exists_, unlike dath ilan, which _does not exist_), is that people mostly drink their own Kool-Aid; lying to the world without lying to yourself is just not psychologically sustainable.

I had some insightful discussion with someone in 2017, in which I was saying that I wanted something to be public knowledge, that was frequently denied for political reasons. (The object-level topic doesn't matter in this context.) This person said, "I don't particularly care about this being commonly recognized. C'mon! It's fun to have some secrets that are not public knowledge".

In 2021, _the same person_ says she feels "disgusted and complicit" for having talked to me.

> At some point during this time I started treating this as a hidden truth that I was proud of myself for being able to see, which I in retrospect I feel disgusted and complicit to have accepted

> above exchanges did in retrospect cause me emotional pain, stress, and contributed to internalizing sexism and transphobia.

I think it's very significant that she _didn't_ say that she encountered _new evidence_ that made her _change her mind_, and decided that she was _actually wrong_ in 2017. The claim is just that the things we said in 2017 are "harmful."

wrap-up dath ilan is fictional

the reason I'm paranoid and humorless about

positive-valence fictional depictions of

"but, but, information can _hurt people_, and hurting people is wrong" and "it's not lying if 'everybody knows'" memes, is because I _actually see this stuff destroying people's minds in real life_

I certainly don't think Yudkowsky is consciously "lying"

(natural language is very flexible, you can _come up with_ some interpretation)

You can cosplay an elf _at a designated fandom convention_, where people have temporarily _opted in_ to that false social reality. But I don't think you can cosplay an elf _at work_ (in "real life") and have everyone play along for extended periods of time, without dealing damage to real-life shared maps.

Similarly, I cosplay female characters at fandom conventions, and that's fun, and I'm glad that conventions exist, but I can't transition in "real life", because I don't expect anyone in real life to believe that I'm female, because it's _very obviously not true_. People will _pretend_ to believe it because they're terrified of being accused of transphobia, but _they are lying_, and the

people who try to claim that no one is being deceived because "everyone knows"

_are also lying_.

Keltham contradicts himself _in the same tag_
https://www.glowfic.com/replies/1865236#reply-1865236

> The sneakiest thing dath ilan did was covertly shape him to never notice he was a sadist
> [...]
> Obviously past-Keltham was shaped in all sorts of ways as a kid, but those shaping-targets are matters of public documentation on the Network.  They're not _covert_ intended effects of the alien technology.

I mean, it's worth noting that their concept of a "good reason" literally includes "prediction markets think people will be happier this way". This is not a Society that gives a shit (as a terminal value) about non-Keepers having accurate information (or they wouldn't, _e.g._, gaslight Merrin about how famous she is).

_Of course_ a Society that prizes freedom-from-infohazards as a core value is going to have lots of "good reasons" for the systematically-misleading-representations they make, that will seem genuinely compelling to the people of that Society who are in on it!

One might have hoped that dath ilani would be self-aware enough to notice that things that seem like a "good reason" for a conspiracy _to dath ilani_, would not seem like a "good reason" to people from a Society that prizes freedom-of-speech? But if they've screened off their history (for the greater good, of course), they might not have a concept of what other Societies are like ...

(Yes, I know we've been informed by authorial fiat that dath ilan has a lot of internal diversity, but there are necessarily limits to that if you're going to be a human Society specifically rather than a Solomonff inductor, and it seems clear that any faction that thinks gaslighting Merrin is morally wrong is on the losing end of the counterfactual warfare of democracy.)

Aslan / amputation of destiny

     * An ethnographer might note that Americans believe themselves to be "the land of the brave and the home of the free", without being obliged for their ethnography to agree with this description. I'm taking the same stance towards dath ilan: as a literary critic, I don't have to share its Society's beliefs about itself.

spoilers for the pleasure of discovering sex for themselves: https://glowfic.com/replies/1812613#reply-1812613

being told eugenics prospects early as self-fulfilling prophecies, as a legitimate infohazard: https://glowfic.com/replies/1812614#reply-1812614

sex and classical mechanics spoilers (spoilers are not the same thing as conspiracies/secrets; Keltham and Carissa arne't supposed to find out): https://glowfic.com/replies/1718168#reply-1718168

https://glowfic.com/replies/1788890#reply-1788890
> He likes confusing people.  Supposedly it's to train strong minds that don't weakly rely on being told how reality works.  I think it may be what dath ilan does with all its repressed sadism.

https://glowfic.com/replies/1801463#reply-1801463
> "I really think all y'all don't give dath ilan enough credit on some dimensions, if not others.  They didn't tell me about my sexual sadism because there would have been no good way for me to satisfy it, Pilar, not because they wanted to deny me my utilityfunction.  Or did you have something else in mind?"

(masochism search tags)
https://glowfic.com/replies/search?board_id=&author_id=366&template_id=&character_id=&subj_content=masochism&sort=created_old&condensed=on&commit=Search

https://glowfic.com/replies/1735044#reply-1735044
> "But yes, or rather, my suspicion is that not many sadists in dath ilan know what they are and Civilization tries to prevent us from finding out, because dath ilan does not have masochists.

> His Lawful Good world tried to make sure he never found out about that.  Keltham thinks that's because dath ilan has no masochists.  He thinks masochism itself is unlikely
https://glowfic.com/replies/1788845#reply-1788845


In the #dath-ilan channel of the server, Yudkowsky elaborated on the reasoning for the masochism coverup:

> altruistic sadists would if-counterfactually-fully-informed prefer not to know, because Civilization is capped on the number of happy sadists. even if you can afford a masochist, which requires being very rich, you're buying them away from the next sadist to whom masochists were previously just barely affordable

In response to a question about how frequent sadism is among Keepers, Yudkowsky wrote:

> I think they're unusually likely to be aware, nonpracticing potential sexual sadists. Noticing that sort of thing about yourself, and then not bidding against the next sadist over for the limited masochist supply, and instead just operating your brain so that it doesn't hurt much to know what you can't have, is exactly the kind of cost you're volunteering to take on when you say you wanna be a Keeper.
> that's archetypally exactly The Sort Of Thing Keepers Do And Are

> They choose not to, not just out of consideration for the next person in line, but because not harming the next person in line is part of the explicit bargain of becoming a Keeper.  
> Like, this sort of thing is exactly what you're signing up for when you throw yourself on the bounded rationality grenade.  
> Let the truth destroy what it can—but in you, not in other people.  

I objected (to the room, I told myself, not technically violating my prior intent to not bother Yudkowsky himself anymore) that "Let the truth destroy what it can—in yourself, not in other people" is such an _incredibly_ infantilizing philosophy. It's a meme that optimizes for shaping people (I know, _other_ people) into becoming weak, stupid, and unreflective, like Thellim's impression of Jane Austen characters. I expect people on Earth—not even "rationalists", just ordinary adults—to be able to cope with ... learning facts about psychology that imply that there are desirable sexual experiences they won't get to have.

A user called Numendil insightfully pointed out that dath ilani might be skeptical of an Earthling saying that an unpleasant aspect our of existence is actually fine, for the same reason we would be skeptical of a resident of Golarion saying that; it makes sense for people from richer civilizations to look "spoiled" to people from poorer ones.

Other replies were more disturbing. One participant wrote:

> I think of "not in other people" not as "infantilizing", but as recognizing independent agency. You don't get to do harm to other people without their consent, whether that is physical or pychological.

I pointed out that this obviously applies to, say, religion. Was it wrong to advocate for atheism in a religious Society, where robbing someone of their belief in God might be harming them?

"Every society strikes a balance between protectionism and liberty," someone said. "This isn't news."


Someone else said:

> dath ilan is essentially a paradise world. In a paradise world, people have the slack to make microoptimisations like that, to allow themselves Noble Lies and not fear for what could be hiding in the gaps. Telling the truth is a heuristic for this world where Noble Lies are often less Noble than expected and trust is harder to come by.

I said that I thought people were missing this idea that the reason "truth is better than lies; knowledge is better than ignorance" is such a well-performing [injunction](https://www.lesswrong.com/posts/dWTEtgBfFaz6vjwQf/ethical-injunctions) in the real world (despite the fact that there's no law of physics preventing lies and ignorance from having beneficial consequences), is because [it protects against unknown unknowns](https://www.lesswrong.com/posts/E7CKXxtGKPmdM9ZRc/of-lies-and-black-swan-blowups). Of course an author who wants to portray an ignorance-maintaining conspiracy as being for the greater good, can assert by authorial fiat whatever details are needed to make it all turn out for the greater good, but _that's not how anything works in real life_.

I started a new thread to complain about the attitude I was seeing (Subject: "Noble Secrets; Or, Conflict Theory of Optimization on Shared Maps"). When fiction in this world, _where I live_, glorifies Noble Lies, that's a cultural force optimizing for making shared maps less accurate, I explained. As someone trying to make shared maps _more_ accurate, this force was hostile to me and mine. I understood that "secrets" and "lies" are not the same thing, but if you're a consequentialist thinking in terms of what kinds of optimization pressures are being applied to shared maps, [it's the same issue](https://www.lesswrong.com/posts/YptSN8riyXJjJ8Qp8/maybe-lying-can-t-exist): I'm trying to steer _towards_ states of the world where people know things, and the Keepers of Noble Secrets are trying to steer _away_ from states of the world where people know things. That's a conflict. I was happy to accept Pareto-improving deals to make the conflict less destructive, but I wasn't going to pretend the pro-ignorance forces were my friends just because they self-identified as "rationalists" or "EA"s. I was willing to accept secrets around nuclear or biological weapons, or AGI, on "better ignorant than dead" grounds, but the "protect sadists from being sad" thing wasn't a threat to anyone's life; it was _just_ coddling people who can't handle reality, which made _my_ life worse.

I wasn't buying the excuse that secret-Keeping practices that wouldn't be okay on Earth were somehow okay on dath ilan, which was asserted by authorial fiat to be sane and smart and benevolent enough to make it work. Alternatively, if I couldn't argue with authorial fiat: the reasons why it would be bad on Earth (even if it wouldn't be bad in the author-assertion paradise of dath ilan) are reasons why _fiction about dath ilan is bad for Earth_.

And just—back in the 'aughts, I said, Robin Hanson had this really great blog called _Overcoming Bias_. (You probably haven't heard of it.) I wanted that _vibe_ back, of Robin Hanson's blog in 2008—the will to _just get the right answer_, without all this galaxy-brained hand-wringing about who the right answer might hurt.

(_Overcoming Bias_ had actually been a group blog then, but I was enjoying the æsthetic of saying "Robin Hanson's blog" (when what I had actually loved about _Overcoming Bias_ was Yudkowsky's Sequences) as a way of signaling contempt for the Yudkowsky of the current year.)

I would have expected a subculture descended from the memetic legacy of Robin Hanson's blog in 2008 to respond to that tripe about protecting people from the truth being a form of "recognizing independent agency" with something like—

"Hi! You must be new here! Regarding your concern about truth doing harm to people, a standard reply is articulated in the post ["Doublethink (Choosing to be Biased)"](https://www.lesswrong.com/posts/Hs3ymqypvhgFMkgLb/doublethink-choosing-to-be-biased). Regarding your concern about recognizing independent agency, a standard reply is articulated in the post ["Your Rationality Is My Business"](https://www.lesswrong.com/posts/anCubLdggTWjnEvBS/your-rationality-is-my-business)."

—or _something like that_. Not that the reply needed to use those particular Sequences links, or _any_ Sequences links; what's important is that someone needed to counter to this very obvious [anti-epistemology](https://www.lesswrong.com/posts/XTWkjCJScy2GFAgDt/dark-side-epistemology).

And what we actually saw in response to the "You don't get to do harm to other people" message was ... it got 5 "+1" emoji-reactions.

Yudkowsky [chimed in to point out that](/images/yudkowsky-it_doesnt_say_tell_other_people.png) "Doublethink" was about _oneself_ not reasonably being in the epistemic position of knowing that one should lie to oneself. It wasn't about telling the truth to _other_ people.

On the one hand, fair enough. My generalization from "you shouldn't want to have false beliefs for your own benefit" to "you shouldn't want other people to have false beliefs for their own benefit" (and the further generalization to it being okay to intervene) was not in the text of the post itself. It made sense for Yudkowsky to refute my misinterpretation of the text he wrote.

On the other hand—given that he was paying attention to this #overflow thread anyway, I might have naïvely hoped that he would appreciate what I was trying to do?—that, after the issue had been pointed out, he would decided that he _wanted_ his chatroom to be a place where we don't want other people to have false beliefs for their own benefit?—a place that approves of "meddling" in the form of _telling people things_.

The other chatroom participants mostly weren't buying what I was selling.

A user called April wrote that "the standard dath ilani has internalized almost everything in the sequences": "it's not that the standards are being dropped[;] it's that there's an even higher standard far beyond what anyone on earth has accomplished". (This received a checkmark emoji-react from Yudkowsky, an indication of his agreement/endorsement.)

Someone else said he was "pretty leery of 'ignore whether models are painful' as a principle, for Earth humans to try to adopt," and went on to offer some thoughts for Earth. I continued to maintain that it was ridiculous that we were talking of "Earth humans" as if there were any other kind—as if rationality in the Yudkowskian tradition wasn't something to aspire to in real life.

Dath ilan [is _fiction_](https://www.lesswrong.com/posts/rHBdcHGLJ7KvLJQPk/the-logical-fallacy-of-generalization-from-fictional), I pointed out. Dath ilan _does not exist_. I thought it was a horrible distraction to try to see our world through Thellim's eyes and feel contempt over how much better things must be on dath ilan (which, to be clear, again, _does not exist_), when one could be looking through the eyes of an ordinary reader of Robin Hanson's blog in 2008 (the _real_ 2008, which _actually happened_), and seeing everything we've lost.

[As it was taught to me then](https://www.lesswrong.com/posts/iiWiHgtQekWNnmE6Q/if-you-demand-magic-magic-won-t-help): if you demand Keepers, _Keepers won't help_.  If I'm going to be happy anywhere, or achieve greatness anywhere, or learn true secrets anywhere, or save the world anywhere, or feel strongly anywhere, or help people anywhere—I may as well do it _on Earth_.

The thread died out soon enough. I had some more thoughts about dath ilan's predilection for deception, of which I typed up some notes for maybe adapting into a blog post later, but there was no point in wasting any more time on Discord.

On 29 November 2022 (four years and a day after the "hill of meaning in defense of validity" Twitter performance that had ignited my rationalist civil war), Yudkowsky remarked about the sadism coverup again:

> Keltham is a romantically obligate sadist. This is information that could've made him much happier if masochists had existed in sufficient supply; Civilization has no other obvious-to-me-or-Keltham reason to conceal it from him.

Despite the fact that there was no point in wasting any more time on Discord, I decided not to resist the temptation to open up the thread again and dump some paragraphs from my notes on the conspiracies of dath ilan.

---------

A user called ajvermillion asked why I was being so aggressively negative about dath ilan. He compared it to Keltham's remark about how [people who grew up under a Lawful Evil government were disposed to take a more negative view of paternalism](https://www.glowfic.com/replies/1874754#reply-1874754) than they do in dath ilan, where paternalism basically works fine because dath ilan is benevolent.

This question put me in a somewhat awkward position: it was a legitimate question that I felt I had to answer, that I had no way of answering honestly without at least _alluding_ to my prior greviances against Yudkowsky ... which were off-topic for the server. (Again, I had told myself that I was here to comment on the story, not to prosecute my greviances.)

I tried to explain, briefly. Someone who might be even _more_ paranoid about abuses of power than someone who grew up with a Lawful Evil government, is someone who grew up under a power structure that put on a _good show_ of being clean and nice, but was actually corrupt and mean.

Yudkowsky had this whole marketing image of him being uniquely sane and therefore uniquely benevolent, and because his Sequences were so life-changingly good, I _actually fell for it_. There was a long Dumb Story (this Story) that was off-topic and I hadn't then finished writing up, but basically, I had what I claimed were very strong reasons not to trust the guy anymore; I think he cares a lot about not explicitly _lying_, but what made the Sequences special is that they articulated a vastly higher standard than that, that he had no intention of living up to.

And so, yeah, insofar as fiction about dath ilan functioned as marketing material for Yudkowsky's personality cult that I thought was damaging people like me (in some ways, while simultaneously helping us in other ways), I had an incentive to come up with literary criticism that paints dath ilan negatively?

It was great for ajvermillion to notice this! It _would_ be bad if my brain were configured to come up with dath-ilan-negative literary criticism, and for me to _simultaneously_ present myself as an authority on dath ilan whom you should trust. But if dath-ilan-negative literary criticism was undersupplied for structural reasons (because people who like a story are selected for not seeing things the story is doing that are Actually Bad), and my brain was configured to generate it anyway (because I disliked the person Yudkowsky had become, in contrast to the person he was in 2008), it seemed pro-social for me to post it, for other people to take or leave according to their own judgement?

The problem I saw with this is that becoming rich and famous isn't a purely random exogenous event. In order to make an informed decision about whether or not to put in the effort to try to _become_ rich and famous (as contrasted to choosing a lower-risk or more laid-back lifestyle), you need accurate beliefs about the perks of being rich and famous.

The dilemma of whether to make more ambitious economic choices in pusuit of sexual goals was something that _already_ happens to people on Earth, rather than being hypothetical. I once met a trans woman who spent a lot of her twenties and thirties working very hard to get money for various medical procedures. I think she would be worse off under a censorship regime run by self-styled Keepers who thought it was kinder to prevent _poor people_ from learning about the concept of "transsexualism".

Further discussion established that Yudkowsky was (supposedly) already taking into account that class of distortion on individuals' decisions, but that the empirical setting of probabilities and utilities happened to be such that ignorance came out on top.


Even if you specified by authorial fiat that "latent sadists could use the information to decide whether or not to try to become rich and famous" didn't tip the utility calculus in itself, [facts are connected to each other](https://www.lesswrong.com/posts/wyyfFfaRar2jEdeQK/entangled-truths-contagious-lies); there were _more consequences_ to the coverup, more ways in which better-informed people could make better decisions than worse-informed people.


Or imagine a world where male homosexuality couldn't be safely practiced due to super-AIDS. (I know very little about BDSM.) I still think men with that underlying predisposition would be better off _having a concept_ of "homosexuality" (even if they couldn't practice it), rather than the concept itself being censored. There are also other systematic differences that go along with sexual orientation (the "feminine gays, masculine lesbians" thing); if you censor the _concept_, you're throwing away that knowledge.

(When I had brought up the super-AIDS hypothetical in the chat, Ajvermillion complained that I was trying to bait people into self-cancelling by biting the bullet on suppressing homosexuality. I agreed that the choice of example was engineered to activate people's progressive moral intuitions about gay rights—it was great for him to notice that—but I thought that colliding philosophical intuitions like that was intellectually productive; it wasn't an attempt to gather blackmail material.)

----

It seemed like the rationale for avoiding spoilers of movie plots or homework exercises had to do with the outcome being different if you got spoiled: you have a different æsthetic experience if you experience the plot twist in the 90th minute of the movie rather than the fourth paragraph of the _Wikipedia_ article. Dath ilan's sadism/masochism coverup didn't seem to have the same structure: when I try to prove a theorem myself before looking at how the textbook says to do it, it's not because I would be _sad about the state of the world_ if I looked at the textbook; it's because the temporary ignorance of working it out myself results in a stronger state of final knowledge.

That is, the difference between "spoiler protections" (sometimes useful) and "coverups" (bad) had to do with whether the ignorant person is expected to eventually uncover the hidden information, and whether the ignorant person knows that there's hidden information that they're expected to uncover. In the case of the sadism/masochism coverup (in contrast to the cases of movie spoilers or homework exercises), it seemed like neither of these conditions pertained. (Keltham knows that the Keepers are keeping secrets, but he seems to actively have beliefs about human psychology that imply masochism is implausible; it seems more like he has a false map, rather than a blank spot on his map for the answer to the homework exercise to be filled in.) I thought that was morally relevant.

(Additionally, I would have hoped that my two previous mentions in the thread of supporting keeping nuclear, bioweapon, and AI secrets should have already made it clear that I wasn't against _all_ cases of Society hiding information, but to further demonstrate my ability to generate counterexamples, I mentioned that I would also admit _threats_ as a class of legitimate infohazard: if I'm not a perfect decision theorist, I'm better off if Tony Soprano just doesn't have my email address to begin with, if I don't trust myself to calculate when I "should" ignore his demands.)

-----

https://discord.com/channels/936151692041400361/954750671280807968/1210280210730061854
> I wouldn't say [the history Screen is] just a plot device and I can see the real dath ilan doing it; Earth definitely shouldn't bother considering it, though.


https://x.com/ESYudkowsky/status/1786189840998117403
> Dath ilani physics textbooks for kids are written from a place of not just demanding or expecting that kids will believe what a textbook says; they try to anticipate the most common skeptical questions about ideas like gravity.

https://x.com/ESYudkowsky/status/1787154210024546687
> Being eliezera, they have a huge number of potential BDSM!sadists and very few masochists.  They'd like people like Keltham to have the option of not learning about nice things they can extremely-probably never have.  You could potentially expose yourself to all the infohazards like that, and end up very sad and possibly choosing early cryonic suspension.  Though to learn information hazardous to others and then go on residing in standard cities and having a default Network credential, you'd also want a prediction market to predict to that city and to Network hosts that you would not tell unconsenting others about the potentially learner-saddening information you'd learned.

https://x.com/ESYudkowsky/status/1787158254285697511
> Dath ilan did not have the thing with the Harry Potter book 6 spoiler Internet meme of "[deleted] dies".  If you told them that this spoiler had run rampant on Earth, they'd make some understated but correct guesses about what other collective-action issues Earth couldn't solve.

https://x.com/ESYudkowsky/status/1787158565754741166
> Does it actually take a lot of work to prevent trolls from ruining Harry Potter Book 6 for everyone?  Do you actually have to design your whole Network architecture and even your cities that way?  Yes!  But dath ilani will not accept a collective inability to have nice things.


### Replies to Objections

This essay has had some negative things to say about dath ilani culture.



#### Infohazardville




#### 


[TODO—
  * Counterargument: dath ilan lets you immigrate to infohazardville. Reply: sure, I agree that a Society that marginalizes truth-tellers is better than one than executes them. It's still fundamentally fair game for me to point out that it's not consilient with the values of _Overcoming Bias_ readers in 2008.
  * Counterargument: as a reductio, am I opposed to movie and homework exercise spoilers, too? Reply: No, I recognize spoiler protection as a legitimate class of infohazard. (And AGI/nuclear as an social exfohazard, and threats as a legitimate infohazard.) And the concealing eugenics predictions, self-fulfilling prophecy
  * Counterargument: the text says that regular dath ilani do believe "that which can be destroyed" eventually, just not immediately. Reply: this would be more believable with a timetable; I can understand "I don't want to deal with this yet", but there's no indication that Merrin or Keltham are supposed to figure it out.
  * Counterargument: but the gaslighting is supposed to inculcate distrust of authority. Reply: clearly it doesn't work, given how much everyone trusts the government that is lying to them all the time?
  * Numendil's point: dath ilani should look spoiled to us, for the same reason we look spoiled to Golarionites
]

### Conclusion

> That's the point where it starts to look like somebody is trying to hide something, or fool future generations, and not just respond to a strange threat in a way where they're happy to let you take all the precautions required to make sure nobody's fooling anybody.
https://www.glowfic.com/replies/1813073#reply-1813073


https://www.glowfic.com/replies/1799590#reply-1799590
> 'That which can be destroyed by the truth should be', goes the proverb, and ordinary dath ilani and Keepers alike both hold to it in the limit.  If you look at it from the standpoint of the Future, if you somehow get some wrong thought into your head, do you want to still be thinking it a thousand years later?  Do you always want to be that small, or that warped, that you could go on holding a false belief forever?
>
> For the ordinary dath ilani, though, they say, 'That which can be destroyed by the truth should be eventually.'
>
> And the Keepers say, 'That which can be destroyed by the truth should be immediately.'
>
> - though, to be clear, that doesn't mean they run around telling other people truths that will wreck parts of their personalities.  It means that they themselves will destroy whatever of themselves they can, with whatever truths they've come to hold.

### Kitchen Knives

[TODO—

     * Word of God says, "there's also a deliberate semiconspiracy whereby movies make standard kitchen knives look much deadlier and easier to wield than they actually are, so that people who suddenly go nuts won't improvise much more dangerous weapons than that"
     * "too nuts to see past cached thoughts" presupposes a specific model of mental illness that I think is importantly backwards; while I was psychotic, my problem was the _opposite_ of not being able to "see past cached thoughts": on the contrary, I was having _lots_ of new ideas that I had never thought of before (<http://zackmdavis.net/blog/2017/02/cognitive-bayesian-therapy-i/>), and would never have thought of in my normal state—it's just that, after I got some sleep, I decided that all of my new ideas were clearly false, _which is why_ we call the psychotic state "crazy", and the normal state "sane".
         * You can't leak to the general public without leaking to crazy people. Where do you think they come from?
     * the mechanism by which the plan positively contributes to the goal, is deception: the plan works _because_ if people who want to commit violence have _less accurate beliefs_ about how to effectively commit violence, they will be less effective at their goal of committing violence.
     * If you were just trying to reduce murders, is this hte plan you would pick? Obviously not. (Think about how you would solve the problem "on Earth"!) Making it easier to commit people is a much more direct mechanism. The algorithm that promoted the movie-misportrayal to your attention is one that favors deception.
         * "It's targeted at crazy people" excuse suggests that it's OK to lie to people you've labeled as crazy. But Yudkowsky infamously says this about all Earthlings. What should we infer about whether we should trust him?
     * "i presume ilani who notice the trope also then deduce the obvious consequence of the trope"
         * If anything, "there's a deliberate conspiracy to mislead people about the difficulty of murder by stabbing" is the kind of thought that someone is _more likely_ to have as a paranoid delusion than otherwise! It's as if dath ilan is an exotic environment where mind-states that are tuned to hypothesize conspiracies everywhere are _adaptive_, in contrast to how on Earth, people who see conspiracies everywhere are wrong.
         * this is correlated insanity that loves clever deceptions, not actually being smart and doing a neutral policy search
     * A much larger cost is the frustration of ornery, nitpicky nerds who _want realistic fiction_, and don't want their favorite artform perverted to _manipulate extremely rare criminal-insanity cases_. Earth has Andy Weir fans and Greg Egan fans! When Andy Weir or Greg Egan sit down to write a novel or a screenplay, they are trying to paint a picture of _a world that makes sense_. They are not trying to manipulate rare social outcomes. Is that that kind of respect-for-reality just _not a thing_ in dath ilani art? Are they so uniformly, monomanically obsessed with trolling their perceived inferiors, that the voice of, "Knives Don't Actually Work That Way; Knives Don't Actually Work That Way _Even When Saying That Out Loud Increases Murders_; Knives Don't Actually Work That Way _Even When a Prediction Market Says That Saying That Out Loud Increases Murders_", has no power in the movie industry whatsoever?
]



> When the words Boundary-Edge are glued together into a special term, what they've come to mean - by processes of mere convention rather than explicit decision, a form of linguistic drift that happens even in dath ilan - is 'Cartesian Environment', the Environment as falsely distinguished from the Agent by a boundary, an edge, which does not ultimately exist within the territory.
