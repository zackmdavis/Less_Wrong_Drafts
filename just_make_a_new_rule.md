# Just Make a New Rule!

"Rules" are a critical social technology for helping people live and work together in peace. From the laws passed by legislatures to govern a whole nation, to the bylaws of a neighborhood homeowner association, to the informal household rules of a single family, rules make it clear what behavior is required and what behavior is forbidden, without otherwise controling every minute detail of everyone's behavior. When there are clear rules, people don't have to drive themselves crazy contorting themselves into unnatural shapes to satisfy the whims of some distant authority. All you have to do is make sure to obey the rules. With that taken care of, you can go about living your life the way you see fit, in freedom and dignity. As can be attested in the annals of human experience from the time of Hammurabi into the present day, it mostly works pretty great! In summary, rules are good. It's good to have clear rules, and for people to obey the rules.

Normal people understand this pretty well and don't need to read a blog post about it, but some people who aren't normal have a theoretical objection. The space of _all possible behaviors_ is unthinkably vast. What if the formidable intelligence of an adversary who hates everything our Society stands for, comes up with a behavior that's really bad, but isn't forbidden by any of Society's rules?

The normal person is unfazed by the theoretical objection. If that happens, you could just make a new rule forbidding that behavior, right? How hard could that be?

The people who aren't normal are unimpressed with this reply. They can tell that the normal person doesn't understand the vastness of the space of possible behaviors at all. If you just make a new rule, surely the formidable intelligence of the adversary will contrive some other eldritch behavior that minimizes Society's utility function while complying to the letter of all of Society's rules. The theory of [nearest unblocked strategies](https://www.lesswrong.com/posts/Q6FPpGxmGaxbSBHSt/nearest-unblocked-strategy-versus-learning-patches) in the lore of AGI alignment, and the specter of [specification gaming](https://deepmind.google/discover/blog/specification-gaming-the-flip-side-of-ai-ingenuity/) in the practice of ML engineering, makes it clear that this is so. Thus, rules won't suffice; we need to empower leaders with the Authority to make judgement callsâ€”even to control the minute details of anyone's behavior, if that's what it takes to safeguard Society's Values.

Now me, I'm normal on my mother's side, which puts me in a good position to understand what both parties to the disagreement are saying. And while my full belief-state about related topics in the theory of decision and optimization is nuanced and complex, on the narrow question of what to do about rules in human Society, I think the normal people have it basically right, and the people who aren't normal are being scared of ghosts. Let me explain. 

I do not dispute the lore of AGI alignment, nor the practice of ML engineering. But crucially, the function of rules in human communities is highly disanalogous to the function of a utility or reward function in AI. Rules aren't supposed to be a complete specification of Society's true Values. The Values live in the hearts of Society's individual women and men, to be expressed in the way they go about living their lives the way they see fit, in freedom and dignity. The rules are just there to stop ourselves from trying to kill each other when your freedom and dignity is getting in the way of my freedom and dignity. You don't _want_ the rules to be a specification of Society's Values (let alone a complete specification robust to nearest unblocked strategies); you want the rules to prevent conflicts among people, so that the people can focus on creating Value instead of wasting time fighting with each other.

The theory of nearest unblocked strategies can be relevant to rules in human Society to the extent that the outcome that a rule was intended to ensure is something that people directly oppose [terminally rather than instrumentally](https://www.lesswrong.com/posts/n5ucT5ZbPdhfGNLtP/terminal-values-and-instrumental-values). For example, income tax laws are passed so that the government will have more money and people will have less money. But people really don't like having less money, so they put the full force of their effort and ingenuity into side-stepping the law by underreporting cash transactions, hiding money in offshore accounts, recategorizing consumption as business expenses, _&c._

But more often, the outcome that a rule is intended to ensure isn't something that people terminally oppose. The rule merely restricts behavior that people would otherwise engage in instrumentally, which they can and will avoid in order to comply with the rule.

Consider laws banning lead paint. Paint manufacturers are not environmental lead maximizers. They're not trying to increase the amount of lead in the environment in the way that people try to increase the amount of money they have.

Rather, they happened to use lead paint because [...]

_(Thanks to Ben Pace and Robert Mushkatblat for discussion.)_
