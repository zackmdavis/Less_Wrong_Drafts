## Athenian Soccer Team Hullabaloo

> Would you smile to see him dead? Would you say, "We are rid of this obscenist"? Fools! The corpse would laugh at you from its cold eyelids! The motionless lips would mock, and the solemn hands, the pulseless, folded hands, in their quietness would write the last indictment, which neither Time nor you can efface. Kill him! And you write his glory and your shame! Moses Harman in his felon stripes stands far above you now, and Moses Harman _dead_ will live on, immortal in the race he died to free! Kill him!
>
> —Voltairine de Cleyre, ["Sex Slavery"](https://praxeology.net/VC-SS.htm)

### The Wisdom of Socrates

Call me Xenophon. This is a tribute to my friend and teacher Socrates, the wisest man in Cyber-Athens.

The choice of adjective is deliberate. Socrates is not the most quick-witted, nor the most knowledgable, nor the most savvy. Rather, the nature of his peculiar talent is this: _he knows what he doesn't know._

Most people don't. At least, I don't. All too often, when asked, "Do you get what I'm saying?", I reply, "I think so" with perfect sincerity, only realizing later that I was deluding myself—that I could not have paraphrased my interlocutor's ideas, let alone explained where I agreed or disagreed with them. In retrospect (and _only_ in retrospect), it's clear that I didn't want to disrupt the harmonious give-and-take flow of social exchange, that I feared being seen as foolish or obstinate for having the temerity to say, "No, I don't understand"—and to continue standing by that _No_ should understanding not be forthcoming.

The unique genius of Socrates is simply that he's not afraid to be seen as foolish or obstinate. If he doesn't understand how you're using a term, he'll ask for a definition. If he doesn't see how to apply your abstract claim, he'll ask for an example. If your offered definition or example doesn't make sense to him, he'll say so. _Bluffing doesn't work on him._

Occasionally it strikes me as a little odd when Socrates asks something that I think he should have been able to figure out by himself, but it's no trouble. If I can spare the time, I'm usually happy to type up the requested additional explanation. If I can't spare the time, there's a chance someone else in the cyber-agora might pitch in and supply it.

But if I can spare the time but can't come up with an explanation that will satisfy Socrates, that's an alarming warning sign that my grasp of the topic isn't as firm as thought: I didn't know what I didn't know.

That's not a hard-and-fast rule that every critical or questioning comment demands a reply. There is such a thing as trolling, and [isolated demands for rigor](https://slatestarcodex.com/2014/08/14/beware-isolated-demands-for-rigor/).

But there's also such a thing as people who combine an above-average need for rigor with a below-average need for social harmony, to the result that they can't be bluffed—who are incredibly valuable to have around to help check that you aren't fooling yourself. Mostly, I figure that if I can't explain it to Socrates, I probably don't understand it.

### Where We Left Off, Re: "Aim for Convergence on Truth, and Behave as if Your Interlocutors Are Also Aiming for Convergence on Truth"

The other year, I got into an incredibly tedious slapfight in the cyber-agora with Meletus, the former curriculum director of the Lyceum. At issue was [my objection to item #5](https://www.lesswrong.com/posts/iThwqe3yPog56ytyq/aiming-for-convergence-is-like-discouraging-betting) on [a list of proposed guidelines for behavior in the cyber-agora](https://www.lesswrong.com/posts/XPv4sYrKnPzeJASuk/basics-of-rationalist-discourse-1) (and [my objection to #9](https://www.lesswrong.com/posts/SX6wQEdGfzz7GKYvp/rationalist-discourse-is-like-physicist-motors) on [a similar list](https://www.lesswrong.com/posts/svuBpoSduzhYjFPrA/elements-of-rationalist-discourse)).

I think all the slapfighting distracted us from getting to the bottom of the issue at hand. Prompted by running into Meletus at a [rare meatspace manifestation of the cyber-agora](http://less.online/) the other week, I'd like to record my reactions to [Meletus's most recent clarification of the motivations for his item #5](https://www.lesswrong.com/posts/9vjEavucqFnfSEvqk/on-aiming-for-convergence-on-truth?commentId=n2J7WgxWodvT8Nt69):

> There are a handful of pieces to the puzzle, including but not limited to:
>
> 1. Good rationalist discourse, as opposed to good unilateralist truth-seeking inquiry, values and prioritizes _some_ kind of _collaboration_. There are many different ways that a good collaborative truth-seeking conversation can look, ranging from sparring/debate to long trying-to-pass-one-another's-ITT's. But there has to be some kind of being-on-the-same-page about how the conversation itself works, some sort of mutual consent regarding the local rules of engagement, or you end up failing to get anything out of the discussion at best, or end up in conflict or wasting time/energy at worst.

There's a trivial sense in which conversations require mutual consent, because people who don't consent exit the conversation. Beyond that, I think I'm much more optimistic than Meletus about getting something out of non-collaborative discussions, where I don't trust you, and you don't trust me, but we each perceive opporunity in continuing to talk (perhaps only the hope of persuading an audience) despite not being on the same page about how the conversation itself should work. The spirit of collaboration is nice when you can get it, but if it's not there, you can't force it—and if it's not there, I [don't think it makes sense to therefore deem the ensuing interaction to not be "rationalist"](https://www.lesswrong.com/posts/SX6wQEdGfzz7GKYvp/rationalist-discourse-is-like-physicist-motors/).

> 2. Setting "convergence with your partner" as the target/goal/thing to optimize for is wrong, as clearly stated in the original post. _Most_ ways of converging are orthogonal to truth; if your intention is to smooth or strengthen a social connection you're not doing truth-seeking.

Agreed.

> 3. It is in fact usually the case that, when two people disagree, each one possesses _some_ scrap of map that the other lacks; it's relatively rare that one person is just right about everything and thoroughly understands and can conclusively dismiss _all_ of the other person's confusions or hesitations. If you are trying to see and understand what's actually true, you should generally be hungry for those scraps of map that other people possess, and interested in seeing, understanding, and copying over those bits which you were missing.

Strongly agreed. (And this is exactly why I'm averse to heavy-handed norm-enforcing moderation. I think that people who don't talk the way that I would prefer them to talk, often know things that I don't. If I were to censor them for failing to conform to the fine details of my idea of collaborativeness, I would lose a chance to discover my mistake.)

> _So from the perspective of being on a forum about clear thinking, clear communication, and collaborative truth-seeking_, i.e. if you came here to play the game that is being played here, there is some combination of prescriptions that goes something like:
>
> 1. Don't be an antagonistic, suspicious, hostile dick; if you don't have some amount of baseline trust and charity for the median LWer then you're in the wrong place. Good faith should not be extended infinitely or blindly; people can in fact prove that they don't deserve it, but you should _start_ from a place of "we're probably both here to try to get closer to the truth" because if you don't, then you're going to ruin the potential for collaboration before it has a chance to be realized. Analogy: don't join a soccer team full of people you do not trust to play soccer well and then immediately refuse to coordinate with them because you think they're untrustworthy teammates.

This doesn't make sense to me, and seems like a crux. "Don't be a hostile dick", okay, sure. But don't be [_suspicious_](https://slatestarcodex.com/2014/06/09/constant-vigilance/)? If you don't have baseline trust and charity for the median person in the cyber-agora, then you're _in the wrong place_?

The problem here is both obvious and fatal. If people in the cyber-agora are wrong, then people who see the error are likely going to distrust them. If you insist that people need to trust you as a prerequisite for even being allowed to talk to you, then you'll never hear from people who don't trust you, which is fatal if the people who don't trust you possess a critical insight that you won't hear from your friends who trust you. If Meletus is sure that people who don't trust him don't have anything worthwhile to say (such that "if you don't have some amount of baseline trust and charity [...] then you're in the wrong place" seems like a good guideline to him), then he possesses vastly more self-confidence than I do.

> 2. That being said, don't prioritize "being a good teammate." Prioritize playing a good game of soccer/doing correct things with the ball. Trust others to receive the ball from you and pass the ball to you until they show you that they don't deserve that trust; don't make "evaluating whether they deserve that trust" or "bending over backwards to prove that you deserve that trust" high priorities. Part of the point of assembling in the garden of LessWrong rather than just doing everything out on the naked internet is that there's a higher baseline of good players around and you can just get down to playing soccer quickly, without a lot of preamble. Figuring out what's true is the actual game, getting closer to truth is the actual goal, and if you're focused on that, you will tend to move closer to others who are also doing that as a side effect.

Broadly agreed, but I'm not entirely sure what the non-metaphorical analogues of "[t]rust[ing] others to receive the ball from you and pass the ball to you" are supposed to be. (Trusting them to listen? Trusting the things they say to be relevant contributions rather than rhetorical traps?)

> 3. Share the labor of making progress with your conversational partners. This loops back to the Zeroth guideline, of expecting it to take some work, but there's a thing where, like, one person sits back and keeps expecting their partner to (basically) do their bidding, and do all of the heavy lifting, and this isn't playing soccer, this is plopping yourself down in the middle of the field and getting in the way of the other people who now have to play soccer around you and tune out your attempts to call plays from a seated position.
>
> (Another way to say this is "it isn't anybody's job to convince or educate you—it's both of your jobs to figure out what's true, and the best way to do that is to hand information back and forth to each other, not to demand that other people hand their information to you.")

I'm ambivalent on this one. [Stonewalling](https://en.wikipedia.org/wiki/Stonewalling) is definitely a potential problem, but I don't want to valorize effort for effort's sake, and there are many use-cases where a labor asymmetry just makes sense. Dividing [interpretive labor](https://acesounderglass.com/2015/06/09/interpretive-labor/) roughly evenly seems desirable in symmetrical situations where both parties have thought-out views on a well-known topic on which they disagree. But when someone writes a post advancing an original thesis that took them many hours to perfect, others can hardly be expected to match that effort before commenting on the work. If I'm presenting a proof of a purported new theorem, and an audience member points out, "Didn't you just divide by zero there?", it seems like it's on me to address that, because it's "my" theorem (even if addressing it entails me doing even more work, while the commenter has done very little).

### Athenian Food Safety Contretemps

After Meletus and Socrates got into another slapfight in [a discussion about the archons changing the laws of the cyber-agora](https://www.lesswrong.com/posts/kyDsgQGHoLkXz6vKL/lw-team-is-adjusting-moderation-policy?commentId=dynr3Pi6Qh2JLLfpD), Meletus wrote a post, ["Killing Socrates"](https://www.lesswrong.com/posts/JcgtKunqmELefxksx/killing-socrates), arguing that the culture of the cyber-agora rewards criticism too much, which discourages valuable potential contributors:

> There are a lot of LessWrong commenters who respond to perceived falsehoods with what looks a lot like an elevated sense of _threat_. "Don't let that one through! That one's _wrong_!"
>
> But many of the actual claims being responded to in this fashion are not powerful snippets of propaganda, or nascent hypnotic suggestions, or psychological Trojan horses. They aren't the workings of an antagonist. They're just half-baked ideas, and you can _either_ respond to a half-baked idea by helping to bake it properly ...
>
> ... or you can shriek "food poisoning!" and throw it in the trash and shout out to everyone else that they need to watch out, someone's trying to poison everybody.
>
> (Or pointedly interrogate the author on why exactly they chose to bake their idea this way when it's so clearly inadequate, would you please explain what made you think that this dough was sufficiently risen to be worth serving?)
>
> It's the difference between, say, writing [a 3300-word piece about how one section of someone else's building is WRONG](https://www.lesswrong.com/posts/iThwqe3yPog56ytyq/aiming-for-convergence-is-like-discouraging-betting), and spending 3300 words suggesting a replacement that might solve the perceived problem better, without containing Flaw X or causing Negative Side Effect Y.

This distinction does not seem intellectually substantive to me. The claim that a building section contains Flaw X and causes Negative Side Effect Y amounts to a claim that the section is wrong (specifically, because it contains a flaw and causes a negative side effect). Is there a difference between describing an object as "wet" and ["covered or impregnated with liquid"](https://en.wiktionary.org/wiki/wet#Adjective)? Maybe, but it's not clear why anyone would care unless they had some obscure form of mental illness that makes them averse to calling wet things wet.

I'll agree that "constructive" criticism that suggests how to fix a half-baked idea ("You need to put it in the oven for longer") is more valuable than criticism that merely identifies flaws. But the reason the constructive criticism is better (if correct) is because it makes a larger direct contribution to the production of fully-baked ideas: knowing what's broken and how to fix it is a strict superset of merely knowing what's broken.

But "Killing Socrates" doesn't seem to be concerned with direct contributions to intellectual production, only indirect (negative) contributions that route through the feelings of authors who require "an atmosphere of collaboration rather than one of evaluation and judgment." The baking metaphor focuses on the harm done by false accusations of intentional poisoning, rather than whether the bakery's products are in fact safe to eat.

On a similar theme, replying to a comment elsewhere on the behavior of alleged cranks who criticize by asking questions, [Meletus writes](https://www.lesswrong.com/posts/9DhneE5BRGaCS2Cja/moderation-notes-re-recent-said-duncan-threads?commentId=wqWh6rXayn65LZJku):

> And this attitude is _particularly_ corrosive to feelings of trust, collaboration, "jamming together," etc. ... it's like walking into a martial arts academy and finding a person present who scoffs at both the instructors and the other students alike, and who doesn't offer sufficient faith to even try a given exercise once before first a) hearing it comprehensively justified and b) checking the sparring records to see if people who did that exercise win more fights.
>
> Which, yeah, that's one way to zero in on the best martial arts practices, _if_ the other people around you also signed up for that kind of culture and have patience for that level of suspicion and mistrust!
>
> (I choose martial arts specifically because it's a domain _full_ of anti-epistemic garbage and claims that don’t pan out.)
>
> But in practice, few people will participate in such a martial arts academy for long, and it's not true that a martial arts academy lacking that level of rigor makes _no_ progress in discovering and teaching useful things to its students.

This comment is striking in that, although it appears to take the form of a sharp critique of the Socratic method, on a close reading, there isn't obviously anything here for Socrates or me to disagree with: in accordance with [the agreement theorem](https://en.wikipedia.org/wiki/Aumann%27s_agreement_theorem) and Meletus's guideline #5, our beliefs seem to be converging. Meletus's complaint about the Socratic method is not that it fails to achieve its aims, but that it's unpopular. Well, sure. Socrates's students aren't trying to be popular; we're trying to converge on the best martial arts practices. In defense of his own methods, Meletus doesn't claim to attain a standard of excellence that the Socratics cannot meet, but merely that "it's not true that [non-Socratic methods] make[ ] _no_ progress in discovering and teaching useful things." Well, sure. Who said otherwise? That's not a particularly high bar!

### Appeals to Consequences and the Citadel of Truth

But the previous section is a dodge. So far, I haven't addressed the core concern raised in "Killing Socrates", that a culture of evaluation and judgment rather than collaboration drives away contributors. This is ultimately an empirical question about the psychology of potential contributors, and [a comment on "Killing Socrates" contrasting the experience of running a summer program nearby and far away from the cyber-agora](https://www.lesswrong.com/posts/JcgtKunqmELefxksx/killing-socrates?commentId=e2EfnDj7f7vZrFGhF) suffices to illustrate that the effect is real. I can opine that the difference between collaborative and non-collaborative feedback is "not intellectually substantive" as I would construe that, but I'm not going to play dumb and pretend that I have no idea what Meletus is talking about. It's not that I [can't see the difference](https://www.lesswrong.com/posts/7Pq9KwZhG6vejmYpo/the-metaphor-you-want-is-color-blindness-not-blind-spot); it's that I'm ideologically committed to ignoring it.

I owe Meletus and his supporters an explanation as to why. Why am I digging in my heels on this? If I agree that it's possible for contributors to be driven away by non-collaborative feedback, why am I not only not disposed to alter my behavior, but to all appearances am not even interested in assessing the empirical extent of the issue? (Think of it as an optimization problem: if the customs of the cyber-agora haven't already been carefully tuned to maximize quality-weighted contributions, it's plausible that there's some nonzero _x_ and _y_ for which being _x_% more collaborative would retain the marginal _y_% of contributors who are alienated by non-collaborativeness.) Is this not irrational? What principle could possibly outweigh the dictum that decisions are to be made according to the expected consequences?

I claim that there is such a principle, which is this: [appeals to consequences](https://www.lesswrong.com/posts/P3FQNvnW8Cz42QBuA/dialogue-on-appeals-to-consequences) are [normatively](https://sarahconstantin.substack.com/p/normativity-and-anti-normativity) invalid. If A implies B, and B is false, then [it follows that](https://en.wikipedia.org/wiki/Modus_tollens) A is false. If the cyber-agora's collective information processing is to reach true conclusions, its deliberations need to systematically mirror this kind of [locally valid](https://www.lesswrong.com/posts/WQFioaudEH8R7fyhm/local-validity-as-a-key-to-sanity-and-civilization) reasoning. "Socrates's un-collaborative insistence that B is false drives away potential contributors and should therefore be censored" may be valid consequentialist reasoning about how to promote feelings of trust, collaboration, and "jamming together", but it's not valid reasoning _about the original subject matter_ of whether A and B are true.

Meletus feels strongly that the cyber-agora should be a [well-kept garden](https://www.lesswrong.com/posts/tscc3e5eujrsEeFN4/well-kept-gardens-die-by-pacifism), that letting Socrates speak has changed the place for the worse:

> The end result of Socrates Unchecked is not, in fact, a bastion of pure reason and untainted truth. That's a [fabricated option](https://www.greaterwrong.com/posts/gNodQGNoPDjztasbh/lies-damn-lies-and-fabricated-options), like believing that a ban on price gouging during a disaster will result in the normal amount of gasoline being available at the normal prices.
>
> What happens instead, in practice, is [evaporative cooling](https://www.greaterwrong.com/posts/ZQG9cwKbct2LtmL3p/evaporative-cooling-of-group-beliefs), as the most sensitive or least-bought-in of [the authors/builders who made your subculture worth participating in in the first place] give up and go elsewhere, marginally increasing the ratio of critics to makers, which makes things marginally less rewarding, which sends the next bunch of builders packing, which worsens the problem further.

As it happens, students of the Socratic tradition [also sometimes worry about evaporative cooling effects](https://www.lesswrong.com/posts/xqAnKW46FqzPLnGmH/causal-reality-vs-social-reality?commentId=qao4Cy4GxD5bsDHDS). Those who haven't been following the conflict carefully might assume that the situation is symmetrical, that the Socratics and Meleteans simply have different preferred cultural norms: that the Meleteans prefer a collaborative vibe, whereas the Socratics prefer a more adversarial one, but the choice is ultimately arbitrary.

But I think [we're not so similar](https://homosabiens.substack.com/p/were-not-so-similar-you-and-i), us Socratics and the Meleteans.

From the Socratic perspective, Meletean moderation policy selects against people who care more about getting to the truth than about maintaining feelings of feelings of trust and collaboration. When I write about the importance of attending to criticism, it's not because I have a perverse æsthetic sense that prizes suspicion and mistrust for their own sake, to put steel into our souls. Rather, I mean it in the same sense that [a computer program for calculating the bias of an unfair coin will get the wrong answer](https://www.lesswrong.com/posts/fmA2GJwZzYtkrAKYJ/algorithms-of-deception) if you don't show it all of the Tails outcomes. The consequence that ignoring counterarguments makes you get the wrong answer is a fact about reality, not an arbitrary cultural convention.

"Killing Socrates" laments that the cyber-agora used to be a place where "builders offer[ed] critique to each other", that Socrates is "siphoning status without making a corresponding contribution." I could see this making sense if the cyber-agora is a kind of [LARP](https://en.wikipedia.org/wiki/Live_action_role-playing_game): if the current rules of the game give outsized rewards to a degenerate strategy that makes the game less fun for everyone, then by all means, we should change the rules.

But if the purpose of the cyber-agora is to implement a truth-tracking discourse, then we can't change the rules to make the game more fun, because [the rules aren't up to us](https://www.lesswrong.com/posts/eY45uCCX7DdwJ4Jha/no-one-can-exempt-you-from-rationality-s-laws). The epistemic function of criticism is to correct errors. If a criticism is correct, it's [irrelevant whether](https://www.lesswrong.com/posts/5yFRd3cjLpm3Nd6Di/argument-screens-off-authority) the person making it is themselves a "builder". If the Meleteans don't want to hear criticism from non-builders because that ruins their game, then their game must be prioritizing something else over truth.

Most games are. The Socratic analogue of the well-kept garden is [the Citadel of Truth](https://www.lesswrong.com/posts/P3FQNvnW8Cz42QBuA/dialogue-on-appeals-to-consequences?commentId=rdcxfgrqGuxyu2DGJ): one goddamned place in the entire goddamned world dedicated _solely_ to the pursuit of truth, committed to ignoring other concerns, like whether publicizing the truth outside the Citadel might cause harm or whether participants feel respected.

The Socratics seek to preserve the cyber-agora as an instance of the Citadel. Ultimately, Meletus is correct to notice that the Citadel is going to miss out on the contributions of people who sustain psychic damage from its customs. To be clear, they're welcome to stay—but the moderators aren't going to protect anyone from non-builder criticism. It's a [fabricated option](https://www.lesswrong.com/posts/gNodQGNoPDjztasbh/lies-damn-lies-and-fabricated-options) to imagine that they could.

### Strawmanning _vs_. Motte-and-Bailey Failure Modes

At this point, the Meleteans are probably not impressed with this post. Meletus's focus on colaborativeness stems from a deep concern about the ubiquitous discourse failure mode of strawmanning, where people argue against their own hostile misinterpretations rather than their interlocutor's real views. (Meletus accuses [me, Xenophon, of being particularly skilled at tricking audiences into thinking that an author said something that they didn't](https://www.lesswrong.com/posts/SX6wQEdGfzz7GKYvp/rationalist-discourse-is-like-physicist-motors?commentId=KfaQnBtqpZym3jkSw).)

A technique for preventing strawmanning is [the Ideological Turing Test](https://www.econlib.org/archives/2011/06/the_ideological.html), in which one attmepts to present one's interlocutor's point of view in one's own words as cogently and persuasively as the interlocutor themself can. If you can't even explain the thing you're purportedly arguing against, goes the idea, you probably don't understand it. In this post, I've sometimes characterized the Meleteans' policies in ways that the Meleteans themselves likely wouldn't agree with: for example, when I claimed that the Meleteans' objection to the Socratic method is "that it's unpopular", or that "their game must be prioritizing something else over truth." Since the Meleteans probably don't think of themselves as objecting to things because they're unpopular or as prioritizing something else over truth, does it not therefore follow that I have misunderstood them, and am only arguing against a strawman of my own construction?

I argue: No, because while I agree that strawmanning is a ubiquitous failure mode and that the ITT is often a useful technique for combatting it, the passages in question weren't part of an ITT attempt. (The ITT is testing your ability to simulate and therefore understand the interlocutor's view; you don't have to _believe_ it.) My claim isn't that the Meleteans _think of themselves_ as prioritizing popularity and collaborative feelings over truth. Obviously, the Meleteans think that prioritizing collaborativeness will lead to truth. I'm claiming that they're wrong about what their own methods imply. And the way I think I know enough about their methods in order to make that judgement (despite the fact that I'm not a mind-reader and can't know what's truly in their heart) is by ... reading the actual text that they actually published, and making logical inferences from the literal meaning of the text?

Meletus didn't say "The Socratic method is bad because it's unpopular" _in those words_, which would sound bad, but complaining that "few people will participate in such a martial arts academy for long" amounts to the same thing. (_Unpopular_, adjective, ["Not liked or popular; disliked or ignored by the public."](https://en.wiktionary.org/wiki/unpopular)) Meletus didn't say "I value feelings of trust and collaboration at the expense of truth" _in those words_, which would sound bad. But if you write essays about how criticism undermines feelings of trust and collaboration, I can't help but notice the revealed preference ordering, even if the author doesn't seem to be aware of it.

Perhaps some readers will still be unsatisfied at my interpreting Meletus's words in a way that Meletus probably wouldn't approve of—that I'm doubling down on the strawmanning ways that Meletus condemns me for, despite paying lip service to the ITT being a useful idea.

But that's just the thing: _that_ description is characterizing _my_ policies in a way that _I_ don't agree with. (I don't think of myself as doubling down on strawmanning.) Besides strawmanning, another ubiquitous form of discourse failure is [the motte-and-bailey doctrine](https://slatestarcodex.com/2014/11/03/all-in-all-another-brick-in-the-motte/), where people opportunistically pivot between different "intended" interpretations of their words.

Unfortunately, the existence of the motte-and-bailey failure mode makes it untenable for criticisms to only be considered admissible if the criticized author agrees with the critic's interpretation of the author's views: it's too easy to stand in the bailey 

stand in the motte and say, "That's a strawman" to all critics.


and yet I consider it _my_ responsibility to explain what the difference is, rather than insisting that my critics need to be pre-emptively charitable to me.


(The difference is that [I think it's not strawmanning if you can explain to third parties how your interpretation is grounded in the text itself](https://www.lesswrong.com/posts/5zjucvhSFvp92eYbE/reply-to-duncan-sabien-on-strawmanning); the author is free to clarify that some interpretation wasn't intended, but critics can't be obligated to have somehow figured that out in advance if it wasn't already clear in the text.)


[TODO—
 * I argue No. I agree that strawmanning is a real problem, but the problem with requiring critics to pass an ITT isthat it permits a stonewalling strategy: if someone disagrees with you
 * https://www.lesswrong.com/posts/PxN5iwS2CTCYi4oAP/against-devil-s-advocacy
 * https://www.lesswrong.com/posts/jo5Fhkb7escrYE9cC/on-the-contrary-steelmanning-is-normal-itt-passing-is-niche

 * work in December 2020 disaster earlier in the soccer analogy?
]


### There Is More In You

There's a throwaway line in "Killing Socrates" where Meletus (unendorsedly) brings up a comparison between himself and an Ayn Rand villain:

> From this perspective, Socrates looks much less like a hero whose sharp wit punctured the inflated egos of various Athenian Ayn Rand villains, and much more like someone who found a clever exploit in the system, siphoning status without making a corresponding contribution.

I found this fascinating because [the same comparison had occurred to me independently](https://www.lesswrong.com/posts/vfjptEJ2oahLqRyZz/justice-cherryl). I'm reminded of this passage from _Atlas Shrugged_:

> It was his sudden, angry "so you don't trust me?" snapped in answer to her first, innocent questions that made her realize she did not—when the doubt had not yet formed in her mind and she had fully expected that the answers would resassure her. She had learned, in the slums of her childhood, that honest people were never touchy about the matter of being trusted.
Only "inflated" isn't the right word. The distinguishing character flaw of Ayn Rand villains is their _fragile_ egos.

When you live second-hand through the perceptions of others, 


[TODO:
 * souls that need to be seen and affirmed by others
 * https://www.greaterwrong.com/posts/yepKvM5rsvbpix75G/you-don-t-exist-duncan
 * I'm a social animal, too, but complaining about "siphoning status without making a corresponding contribution" is a sign that you need to chill
 * If you had the choice, wouldn't you prefer not to be fragile?

https://www.lesswrong.com/posts/sCWe5RRvSHQMccd2Q/i-would-have-shit-in-that-alley-too?commentId=tyZiGNA29rBiqfRPw

> Over the mid-to-long term, the only people left in the community would be a small minority of users with really thick skins who care about the truth above all else, along with a sizeable majority of people who enjoy intentionally insulting and lambasting others under the guise of "I'm only calling it as I see it."

]
