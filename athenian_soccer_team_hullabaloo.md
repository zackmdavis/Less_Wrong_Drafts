## Athenian Soccer Team Hullabaloo

> Would you smile to see him dead? Would you say, "We are rid of this obscenist"? Fools! The corpse would laugh at you from its cold eyelids! The motionless lips would mock, and the solemn hands, the pulseless, folded hands, in their quietness would write the last indictment, which neither Time nor you can efface. Kill him! And you write his glory and your shame! Moses Harman in his felon stripes stands far above you now, and Moses Harman _dead_ will live on, immortal in the race he died to free! Kill him!
>
> —Voltairine de Cleyre, ["Sex Slavery"](https://praxeology.net/VC-SS.htm)

Call me Xenophon. This is a tribute to my friend and teacher Socrates, the wisest man in Cyber-Athens.

The word choice is deliberate. Socrates is not the most quick-witted, nor the most knowledgable, nor the most savvy. Rather, the nature of his peculiar talent is this: _he knows what he doesn't know._

Most people don't. At least, I don't. All too often, when asked, "Do you get what I'm saying?", I reply, "I think so" with perfect sincerity, only realizing later that I was deluding myself—that I could not have paraphrased my interlocutor's ideas, let alone explained where I agreed or disagreed with them. In retrospect (and _only_ in retrospect), it's clear that I didn't want to disrupt the harmonious give-and-take flow of primate social exchange, that I feared being seen as foolish or obstinate for having the temerity to say, "No, I don't understand"—and to continue standing by that _No_ should understanding not be forthcoming.

The unique genius of Socrates is simply that he's not afraid to be seen as foolish or obstinate. If he doesn't understand how you're using a term, he'll ask for a definition. If he doesn't see how to apply your abstract claim, he'll ask for an example. If your offered definition or example doesn't make sense to him, he'll say so. _Bluffing doesn't work on him._

Occasionally it strikes me as a little odd when Socrates asks something that I think he should have been able to figure out by himself, but it's no trouble. If I can spare the time, I'm usually happy to type up the requested additional explanation. If I can't spare the time, there's a chance someone else in the cyber-agora might pitch in and supply it.

But if I can spare the time and I can't come up with an explanation that will satisfy Socrates, that's an alarming warning sign that maybe my grasp of the topic isn't as firm as thought: I didn't know what I didn't know.

That's not a hard-and-fast rule that every critical or questioning comment demands a reply. There is such a thing as trolling, and [isolated demands for rigor](https://slatestarcodex.com/2014/08/14/beware-isolated-demands-for-rigor/).

But there's also such a thing as people who combine an above-average need for rigor with a below-average need for social harmony to the result that they can't be bluffed, who are incredibly valuable to have around to help check that you aren't fooling yourself. Mostly, I figure that if I can't explain it to Socrates, I probably don't understand it.

------

The other year, I got into an incredibly tedious slapfight in the cyber-agora with Meletus, the former curriculum director of the Lyceum. At issue was [my objection to item #5](https://www.lesswrong.com/posts/iThwqe3yPog56ytyq/aiming-for-convergence-is-like-discouraging-betting) on [a list of proposed guidelines for behavior in the cyber-agora](https://www.lesswrong.com/posts/XPv4sYrKnPzeJASuk/basics-of-rationalist-discourse-1) (and [my objection to #9](https://www.lesswrong.com/posts/SX6wQEdGfzz7GKYvp/rationalist-discourse-is-like-physicist-motors) on [a similar list](https://www.lesswrong.com/posts/svuBpoSduzhYjFPrA/elements-of-rationalist-discourse)).

I think all the slapfighting got in the way of us getting to the bottom of the issue at hand. Prompted by running into Meletus at a [meatspace manifestation of the cyber-agora](http://less.online/) the other week, I'd like to record my reactions to Meletus's [most recent clarification of the motivations for item #5](https://www.greaterwrong.com/posts/9vjEavucqFnfSEvqk/on-aiming-for-convergence-on-truth/comment/n2J7WgxWodvT8Nt69):

> There are a handful of pieces to the puzzle, including but not limited to:
>
> 1. Good rationalist discourse, as opposed to good unilateralist truth-seeking inquiry, values and prioritizes some kind of collaboration. There are many different ways that a good collaborative truth-seeking conversation can look, ranging from sparring/debate to long trying-to-pass-one-another's-ITT's. But there has to be some kind of being-on-the-same-page about how the conversation itself works, some sort of mutual consent regarding the local rules of engagement, or you end up failing to get anything out of the discussion at best, or end up in conflict or wasting time/energy at worst.

There's a trivial sense in which conversations require mutual consent, because people who don't consent exit the conversation. Beyond that, I think I'm much more optimistic than Meletus about getting something out of non-collaborative discussions, where I don't trust you, and you don't trust me, but we each perceive opporunity in continuing to talk (perhaps only the hope of persuading an audience).

The spirit of collaboration is nice when you can get it, but if it's not there, you can't force it—and if it's not there, I [don't think it makes sense to therefore deem the ensuing interaction to be "not rationalist".](https://www.lesswrong.com/posts/SX6wQEdGfzz7GKYvp/rationalist-discourse-is-like-physicist-motors/)

> 2. Setting "convergence with your partner" as the target/goal/thing to optimize for is wrong, as clearly stated in the original post. Most ways of converging are orthogonal to truth; if your intention is to smooth or strengthen a social connection you're not doing truth-seeking.

Agreed.

> 3. It is in fact usually the case that, when two people disagree, each one possesses some scrap of map that the other lacks; it's relatively rare that one person is just right about everything and thoroughly understands and can conclusively dismiss all of the other person's confusions or hesitations. If you are trying to see and understand what's actually true, you should generally be hungry for those scraps of map that other people possess, and interested in seeing, understanding, and copying over those bits which you were missing.

Strongly agreed. (And this is exactly why I'm averse to heavy-handed norm-enforcing moderation. I think that people who don't talk the way that I would prefer them to talk, often know things that I don't. If I were to censor them for failing to conform to the fine details of my idea of collaborativeness, I would lose a chance to discover my mistake.)

> So from the perspective of being on a forum about clear thinking, clear communication, and collaborative truth-seeking, i.e. if you came here to play the game that is being played here, there is some combination of prescriptions that goes something like:
>
> 1. Don't be an antagonistic, suspicious, hostile dick; if you don't have some amount of baseline trust and charity for the median LWer then you're in the wrong place. Good faith should not be extended infinitely or blindly; people can in fact prove that they don't deserve it, but you should start from a place of "we're probably both here to try to get closer to the truth" because if you don't, then you're going to ruin the potential for collaboration before it has a chance to be realized. Analogy: don't join a soccer team full of people you do not trust to play soccer well and then immediately refuse to coordinate with them because you think they're untrustworthy teammates.

This doesn't make sense to me, and seems like a crux. "Don't be a hostile dick", okay, sure. But don't be [_suspicious_](https://slatestarcodex.com/2014/06/09/constant-vigilance/)? If you don't have baseline trust and charity for the median person on the cyber-agora, the you're _in the wrong place_? No! Why would you think that?!

If people on the cyber-agora are wrong—correlatedly wrong, in sync with each other—then someone who sees the error should not trust them! (If they were trustworthy, they wouldn't be correlatedly wrong like that.) If the people on the cyber-agora furthermore insist that people who don't trust them don't belong there, that's suicidal: enforcing groupthink like that all but assures that the error won't be corrected.

I fear that this objection to the direction to not be an antagonistic, suspicious, hostile dick will be construed as me being an antagonistic, suspicious, hostile dick. Surely, one might reply, I'm responding to a strawman: Meletus would not describe his guidelines as trying to enforce groupthink, so if _I_ describe them that way, it must be an error in my understanding. The relevent concept of "trust" isn't about never being in error, but about intent: the assumption that we're both here to _try_ to get to the truth is necessary for collaboration.

[TODO: talk is cheap; I believe that people in the cyber-agora self-identify as truthseeking, but that doesn't mean I need to model them that way]

> 2. That being said, don't prioritize "being a good teammate." Prioritize playing a good game of soccer/doing correct things with the ball. Trust others to receive the ball from you and pass the ball to you until they show you that they don't deserve that trust; don't make "evaluating whether they deserve that trust" or "bending over backwards to prove that you deserve that trust" high priorities. Part of the point of assembling in the garden of LessWrong rather than just doing everything out on the naked internet is that there's a higher baseline of good players around and you can just get down to playing soccer quickly, without a lot of preamble. Figuring out what's true is the actual game, getting closer to truth is the actual goal, and if you're focused on that, you will tend to move closer to others who are also doing that as a side effect.

Broadly agreed, but I'm not entirely sure what the non-metaphorical analogues of "[t]rust[ing] others to receive the ball from you and pass the ball to you" is supposed to be. (Trusting them to listen? Trusting the things they say to be relevant contributions rather than rhetorical traps?)

> 3. Share the labor of making progress with your conversational partners. This loops back to the Zeroth guideline, of expecting it to take some work, but there's a thing where, like, one person sits back and keeps expecting their partner to (basically) do their bidding, and do all of the heavy lifting, and this isn't playing soccer, this is plopping yourself down in the middle of the field and getting in the way of the other people who now have to play soccer around you and tune out your attempts to call plays from a seated position.
>
> (Another way to say this is "it isn't anybody's job to convince or educate you—it's both of your jobs to figure out what's true, and the best way to do that is to hand information back and forth to each other, not to demand that other people hand their information to you.")

I'm ambivalent about this one. [TODO: explain ambivalence]

------

[TODO: intro to passage from "Killing Socrates"
https://www.greaterwrong.com/posts/JcgtKunqmELefxksx/killing-socrates
]


> There are a lot of LessWrong commenters who respond to perceived falsehoods with what looks a lot like an elevated sense of _threat_. "Don't let that one through! That one's _wrong_!
>
> But many of the actual claims being responded to in this fashion are not powerful snippets of propaganda, or nascent hypnotic suggestions, or psychological Trojan horses. They aren't the workings of an antagonist. They're just half-baked ideas, and you can _either_ respond to a half-baked idea by helping to bake it properly...
>
> ... or you can shriek "food poisoning!" and throw it in the trash and shout out to everyone else that they need to watch out, someone's trying to poison everybody.
>
> (Or pointedly interrogate the author on why exactly they chose to bake their idea this way when it's so clearly inadequate, would you please explain what made you think that this dough was sufficiently risen to be worth serving?)
>
> It's the difference between, say, writing [a 3300-word piece about how one section of someone else's building is WRONG](https://www.greaterwrong.com/posts/iThwqe3yPog56ytyq/aiming-for-convergence-is-like-discouraging-betting), and spending 3300 words suggesting a replacement that might solve the perceived problem better, without containing Flaw X or causing Negative Side Effect Y.

[TODO: this difference doesn't seem intellectually substantive to me; the difference Meletus seems to care about is about the speaker's feelings, not whether the food is in fact poisonous!]

------

[TODO: introduce gym statement]

> And this attitude is _particularly_ corrosive to feelings of trust, collaboration, "jamming together," etc. ... it's like walking into a martial arts academy and finding a person present who scoffs at both the instructors and the other students alike, and who doesn't offer sufficient faith to even try a given exercise once before first a) hearing it comprehensively justified and b) checking the sparring records to see if people who did that exercise win more fights.
>
> Which, yeah, that's one way to zero in on the best martial arts practices, _if_ the other people around you also signed up for that kind of culture and have patience for that level of suspicion and mistrust!
>
> (I choose martial arts specifically because it's a domain _full_ of anti-epistemic garbage and claims that don’t pan out.)
>
> But in practice, few people will participate in such a martial arts academy for long, and it’s not true that a martial arts academy lacking that level of rigor makes _no_ progress in discovering and teaching useful things to its students.

This is a remarkable statement. Despite taking on the form of a forceful critique of the Socratic method, it's not clear that there's anything here for me or Socrates to substantively disagree with.

Meletus's complaint about the Socratic method is not that it fails to achieve its aims, but that it's _unpopular_.
